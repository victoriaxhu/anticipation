{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "239e6c9da6b84c339b886ea3ba2b688b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5ef4f7e3b4a4ad8b683ec82ab5934e9",
              "IPY_MODEL_54efff78409942c4b309c1767449d00c",
              "IPY_MODEL_1c1cfc594e54410799230fbc7ae12d31"
            ],
            "layout": "IPY_MODEL_56691a60939f4684b79851559d33a046"
          }
        },
        "b5ef4f7e3b4a4ad8b683ec82ab5934e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76d174a2409a4889ae28f2229cfacfa7",
            "placeholder": "​",
            "style": "IPY_MODEL_bfbf095cf7ec4cd38d4ae8bf40bd41bd",
            "value": "config.json: "
          }
        },
        "54efff78409942c4b309c1767449d00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d9b1cb2b903244b6833506250ee55781",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f1770bbf0dd24175a91e757c3865b119",
            "value": 1
          }
        },
        "1c1cfc594e54410799230fbc7ae12d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83c7c6a32b314c278946586c5dfb0a70",
            "placeholder": "​",
            "style": "IPY_MODEL_ce585cfad938467db0d1588bcc4ffcd1",
            "value": " 1.96k/? [00:00&lt;00:00, 125kB/s]"
          }
        },
        "56691a60939f4684b79851559d33a046": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d174a2409a4889ae28f2229cfacfa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfbf095cf7ec4cd38d4ae8bf40bd41bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d9b1cb2b903244b6833506250ee55781": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "f1770bbf0dd24175a91e757c3865b119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "83c7c6a32b314c278946586c5dfb0a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce585cfad938467db0d1588bcc4ffcd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf91d66a181c46d6be656a7067b35a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b4a5621f88e4a6081c2cc7664163eb0",
              "IPY_MODEL_1883c5c23e3541f79d930ee7bf95dfa2",
              "IPY_MODEL_f0dd59d320224ea8af9177fc3ff80e86"
            ],
            "layout": "IPY_MODEL_656374c70bd94627b0cc0d246d6d83f1"
          }
        },
        "5b4a5621f88e4a6081c2cc7664163eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeb7c52eee074840abd144b413178878",
            "placeholder": "​",
            "style": "IPY_MODEL_314dc1cbbbc74f8c9fc1da70587e5ae5",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "1883c5c23e3541f79d930ee7bf95dfa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7975553ce48f45e5979e6e0e602009c8",
            "max": 512433185,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59cb41c119f44027aa8cb507f4246c52",
            "value": 512433185
          }
        },
        "f0dd59d320224ea8af9177fc3ff80e86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddc77745f5154e10a3dbee6ed700b285",
            "placeholder": "​",
            "style": "IPY_MODEL_fd9060dee584487dbdefce8dff94549c",
            "value": " 512M/512M [00:06&lt;00:00, 70.5MB/s]"
          }
        },
        "656374c70bd94627b0cc0d246d6d83f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb7c52eee074840abd144b413178878": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "314dc1cbbbc74f8c9fc1da70587e5ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7975553ce48f45e5979e6e0e602009c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59cb41c119f44027aa8cb507f4246c52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddc77745f5154e10a3dbee6ed700b285": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd9060dee584487dbdefce8dff94549c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "502ee24939ae45c4a92aa8fd7543e277": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_a7e3bb5f2e034eb4a92d9ae1bd1323fa"
          }
        },
        "6aa381a901e74c16a6a12332fe1f0ba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99610d4dd7214535af16692433252029",
            "placeholder": "​",
            "style": "IPY_MODEL_8068d80be44248bdb3ae887691c0173f",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "02a7f05946d5420bb51b29959b9f02b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b859fa8422a248c88e1515af263a9e6b",
            "placeholder": "​",
            "style": "IPY_MODEL_cd769047da2e4d40a4eea2bd1a848c06",
            "value": ""
          }
        },
        "75ee74ee81e04aabadd8d0553dcc62f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_7ce501b7397a4b33b067170e35d25997",
            "style": "IPY_MODEL_fe7d2e496a3142578a6ea585615cc43d",
            "value": true
          }
        },
        "219aac22ddee4014bdc5e23652225553": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_5a86b62a2ed84900bb3d8e20ab7a1070",
            "style": "IPY_MODEL_fed3df4a2119440abf76c4835d803fc7",
            "tooltip": ""
          }
        },
        "318a82c2379f467da35973919a0f5051": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be30aa9dbfd04d9dbbcd48d5693f2b56",
            "placeholder": "​",
            "style": "IPY_MODEL_7546456bdcc94d4b9cbb82d8807008e2",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "a7e3bb5f2e034eb4a92d9ae1bd1323fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "99610d4dd7214535af16692433252029": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8068d80be44248bdb3ae887691c0173f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b859fa8422a248c88e1515af263a9e6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd769047da2e4d40a4eea2bd1a848c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ce501b7397a4b33b067170e35d25997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe7d2e496a3142578a6ea585615cc43d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a86b62a2ed84900bb3d8e20ab7a1070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fed3df4a2119440abf76c4835d803fc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "be30aa9dbfd04d9dbbcd48d5693f2b56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7546456bdcc94d4b9cbb82d8807008e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "52ea1c9c653b4e54bae594e9b0df342d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24561ea3c6e64646b674a60f317ae518",
            "placeholder": "​",
            "style": "IPY_MODEL_07d4239d2ea5478f9b8c0b4fa08b4cd2",
            "value": "Connecting..."
          }
        },
        "24561ea3c6e64646b674a60f317ae518": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07d4239d2ea5478f9b8c0b4fa08b4cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09f390cb2a0e49fba51ccc9248f6b1ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_23ca6b6077844165ae6935f1c76ef0f6",
              "IPY_MODEL_a01e9bba7af0488a991b3a1fe80e59e2",
              "IPY_MODEL_f843429fbaa54ab3b52e418c4b1ea45c"
            ],
            "layout": "IPY_MODEL_02772708b779489fbd3016f8cece4be8"
          }
        },
        "23ca6b6077844165ae6935f1c76ef0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c53dabe97da42f4b2fade36074f9a4b",
            "placeholder": "​",
            "style": "IPY_MODEL_07a3e849b8c34718b985eebcdb4708c9",
            "value": "config.json: 100%"
          }
        },
        "a01e9bba7af0488a991b3a1fe80e59e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_776603012228490794d738b4fcbcbc4c",
            "max": 1977,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2b0ad9a9b1e94ced86fef42761705af5",
            "value": 1977
          }
        },
        "f843429fbaa54ab3b52e418c4b1ea45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65d2b7066bcd45d4abf156e8e8ecdadc",
            "placeholder": "​",
            "style": "IPY_MODEL_59a2b0d988b948998207cbff18eef0f7",
            "value": " 1.98k/1.98k [00:00&lt;00:00, 62.0kB/s]"
          }
        },
        "02772708b779489fbd3016f8cece4be8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c53dabe97da42f4b2fade36074f9a4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07a3e849b8c34718b985eebcdb4708c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "776603012228490794d738b4fcbcbc4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b0ad9a9b1e94ced86fef42761705af5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65d2b7066bcd45d4abf156e8e8ecdadc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59a2b0d988b948998207cbff18eef0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cacb6295f6949f9ab7f4f27ab66d5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_82a7357516b1417b892c404e8e2425c0",
              "IPY_MODEL_0ca54ee5c4f14e899125704bc5d8a7ec",
              "IPY_MODEL_abf880e81d4d4f5381e5301c1b3d77bf"
            ],
            "layout": "IPY_MODEL_8f79ae468c1e4cc1b6ec65ac2150cd17"
          }
        },
        "82a7357516b1417b892c404e8e2425c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f6fd9cbcf334d67a4ff158f17bea8b1",
            "placeholder": "​",
            "style": "IPY_MODEL_d939f6f2b2be47dea7cd4cc825a0066b",
            "value": "model.safetensors: 100%"
          }
        },
        "0ca54ee5c4f14e899125704bc5d8a7ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57b3d5bded11491b95e9d66bba0d16fd",
            "max": 1438861392,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_508095c4147641b8998b1488d0973e44",
            "value": 1438861392
          }
        },
        "abf880e81d4d4f5381e5301c1b3d77bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e9ca2480bdb46e69ce639e575c6cf26",
            "placeholder": "​",
            "style": "IPY_MODEL_fe62587e496045d9bf4307663df694a0",
            "value": " 1.44G/1.44G [00:13&lt;00:00, 77.0MB/s]"
          }
        },
        "8f79ae468c1e4cc1b6ec65ac2150cd17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f6fd9cbcf334d67a4ff158f17bea8b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d939f6f2b2be47dea7cd4cc825a0066b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57b3d5bded11491b95e9d66bba0d16fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "508095c4147641b8998b1488d0973e44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e9ca2480bdb46e69ce639e575c6cf26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe62587e496045d9bf4307663df694a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Installs"
      ],
      "metadata": {
        "id": "ZMZJmdUFvt_O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fsdE4TbkvBED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66a7002b-9913-47fa-e2c7-e4cc1b444f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  at-spi2-core fluid-soundfont-gm gsettings-desktop-schemas libatk-bridge2.0-0\n",
            "  libatk1.0-0 libatk1.0-data libatspi2.0-0 libdouble-conversion3 libevdev2\n",
            "  libfluidsynth3 libgtk-3-0 libgtk-3-bin libgtk-3-common libgudev-1.0-0\n",
            "  libinput-bin libinput10 libinstpatch-1.0-2 libmd4c0 libmtdev1 libqt5core5a\n",
            "  libqt5dbus5 libqt5gui5 libqt5network5 libqt5svg5 libqt5widgets5\n",
            "  librsvg2-common libwacom-bin libwacom-common libwacom9 libxcb-icccm4\n",
            "  libxcb-image0 libxcb-keysyms1 libxcb-render-util0 libxcb-util1\n",
            "  libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxcomposite1\n",
            "  libxkbcommon-x11-0 libxtst6 qsynth qt5-gtk-platformtheme\n",
            "  qttranslations5-l10n session-migration timgm6mb-soundfont\n",
            "Suggested packages:\n",
            "  fluid-soundfont-gs gvfs qt5-image-formats-plugins qtwayland5 jackd\n",
            "The following NEW packages will be installed:\n",
            "  at-spi2-core fluid-soundfont-gm fluidsynth gsettings-desktop-schemas\n",
            "  libatk-bridge2.0-0 libatk1.0-0 libatk1.0-data libatspi2.0-0\n",
            "  libdouble-conversion3 libevdev2 libfluidsynth3 libgtk-3-0 libgtk-3-bin\n",
            "  libgtk-3-common libgudev-1.0-0 libinput-bin libinput10 libinstpatch-1.0-2\n",
            "  libmd4c0 libmtdev1 libqt5core5a libqt5dbus5 libqt5gui5 libqt5network5\n",
            "  libqt5svg5 libqt5widgets5 librsvg2-common libwacom-bin libwacom-common\n",
            "  libwacom9 libxcb-icccm4 libxcb-image0 libxcb-keysyms1 libxcb-render-util0\n",
            "  libxcb-util1 libxcb-xinerama0 libxcb-xinput0 libxcb-xkb1 libxcomposite1\n",
            "  libxkbcommon-x11-0 libxtst6 qsynth qt5-gtk-platformtheme\n",
            "  qttranslations5-l10n session-migration timgm6mb-soundfont\n",
            "0 upgraded, 46 newly installed, 0 to remove and 41 not upgraded.\n",
            "Need to get 151 MB of archives.\n",
            "After this operation, 220 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libdouble-conversion3 amd64 3.1.7-4 [39.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5core5a amd64 5.15.3+dfsg-2ubuntu0.2 [2,006 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libevdev2 amd64 1.12.1+dfsg-1 [39.5 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmtdev1 amd64 1.1.6-1build4 [14.5 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgudev-1.0-0 amd64 1:237-2build1 [16.3 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-common all 2.2.0-1 [54.3 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom9 amd64 2.2.0-1 [22.0 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput-bin amd64 1.20.0-1ubuntu0.3 [19.9 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libinput10 amd64 1.20.0-1ubuntu0.3 [131 kB]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libmd4c0 amd64 0.4.8-1 [42.0 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5dbus5 amd64 5.15.3+dfsg-2ubuntu0.2 [222 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5network5 amd64 5.15.3+dfsg-2ubuntu0.2 [731 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-icccm4 amd64 0.4.1-1.1build2 [11.5 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-util1 amd64 0.4.0-1build2 [11.4 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-image0 amd64 0.4.0-2 [11.5 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-keysyms1 amd64 0.4.0-1build3 [8,746 B]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-render-util0 amd64 0.3.9-1build3 [10.3 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinerama0 amd64 1.14-3ubuntu3 [5,414 B]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xinput0 amd64 1.14-3ubuntu3 [34.3 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcb-xkb1 amd64 1.14-3ubuntu3 [32.8 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbcommon-x11-0 amd64 1.4.0-1 [14.4 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5gui5 amd64 5.15.3+dfsg-2ubuntu0.2 [3,722 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 libqt5widgets5 amd64 5.15.3+dfsg-2ubuntu0.2 [2,561 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libqt5svg5 amd64 5.15.3-1 [149 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatspi2.0-0 amd64 2.44.0-3 [80.9 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxtst6 amd64 2:1.2.3-1build4 [13.4 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy/main amd64 session-migration amd64 0.3.6 [9,774 B]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu jammy/main amd64 gsettings-desktop-schemas all 42.0-1ubuntu1 [31.1 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu jammy/main amd64 at-spi2-core amd64 2.44.0-3 [54.4 kB]\n",
            "Get:30 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fluid-soundfont-gm all 3.1-5.3 [130 MB]\n",
            "Get:31 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libinstpatch-1.0-2 amd64 1.1.6-1 [240 kB]\n",
            "Get:32 http://archive.ubuntu.com/ubuntu jammy/universe amd64 timgm6mb-soundfont all 1.3-5 [5,427 kB]\n",
            "Get:33 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libfluidsynth3 amd64 2.2.5-1 [246 kB]\n",
            "Get:34 http://archive.ubuntu.com/ubuntu jammy/universe amd64 fluidsynth amd64 2.2.5-1 [27.4 kB]\n",
            "Get:35 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-data all 2.36.0-3build1 [2,824 B]\n",
            "Get:36 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk1.0-0 amd64 2.36.0-3build1 [51.9 kB]\n",
            "Get:37 http://archive.ubuntu.com/ubuntu jammy/main amd64 libatk-bridge2.0-0 amd64 2.38.0-3 [66.6 kB]\n",
            "Get:38 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxcomposite1 amd64 1:0.4.5-1build2 [7,192 B]\n",
            "Get:39 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk-3-common all 3.24.33-1ubuntu2.2 [239 kB]\n",
            "Get:40 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk-3-0 amd64 3.24.33-1ubuntu2.2 [3,053 kB]\n",
            "Get:41 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgtk-3-bin amd64 3.24.33-1ubuntu2.2 [69.6 kB]\n",
            "Get:42 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Get:43 http://archive.ubuntu.com/ubuntu jammy/main amd64 libwacom-bin amd64 2.2.0-1 [13.6 kB]\n",
            "Get:44 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qsynth amd64 0.9.6-1 [305 kB]\n",
            "Get:45 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 qt5-gtk-platformtheme amd64 5.15.3+dfsg-2ubuntu0.2 [130 kB]\n",
            "Get:46 http://archive.ubuntu.com/ubuntu jammy/universe amd64 qttranslations5-l10n all 5.15.3-1 [1,983 kB]\n",
            "Fetched 151 MB in 7s (21.7 MB/s)\n",
            "Extracting templates from packages: 100%\n",
            "Selecting previously unselected package libdouble-conversion3:amd64.\n",
            "(Reading database ... 121713 files and directories currently installed.)\n",
            "Preparing to unpack .../00-libdouble-conversion3_3.1.7-4_amd64.deb ...\n",
            "Unpacking libdouble-conversion3:amd64 (3.1.7-4) ...\n",
            "Selecting previously unselected package libqt5core5a:amd64.\n",
            "Preparing to unpack .../01-libqt5core5a_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libevdev2:amd64.\n",
            "Preparing to unpack .../02-libevdev2_1.12.1+dfsg-1_amd64.deb ...\n",
            "Unpacking libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Selecting previously unselected package libmtdev1:amd64.\n",
            "Preparing to unpack .../03-libmtdev1_1.1.6-1build4_amd64.deb ...\n",
            "Unpacking libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Selecting previously unselected package libgudev-1.0-0:amd64.\n",
            "Preparing to unpack .../04-libgudev-1.0-0_1%3a237-2build1_amd64.deb ...\n",
            "Unpacking libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Selecting previously unselected package libwacom-common.\n",
            "Preparing to unpack .../05-libwacom-common_2.2.0-1_all.deb ...\n",
            "Unpacking libwacom-common (2.2.0-1) ...\n",
            "Selecting previously unselected package libwacom9:amd64.\n",
            "Preparing to unpack .../06-libwacom9_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom9:amd64 (2.2.0-1) ...\n",
            "Selecting previously unselected package libinput-bin.\n",
            "Preparing to unpack .../07-libinput-bin_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libinput10:amd64.\n",
            "Preparing to unpack .../08-libinput10_1.20.0-1ubuntu0.3_amd64.deb ...\n",
            "Unpacking libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Selecting previously unselected package libmd4c0:amd64.\n",
            "Preparing to unpack .../09-libmd4c0_0.4.8-1_amd64.deb ...\n",
            "Unpacking libmd4c0:amd64 (0.4.8-1) ...\n",
            "Selecting previously unselected package libqt5dbus5:amd64.\n",
            "Preparing to unpack .../10-libqt5dbus5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5network5:amd64.\n",
            "Preparing to unpack .../11-libqt5network5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libxcb-icccm4:amd64.\n",
            "Preparing to unpack .../12-libxcb-icccm4_0.4.1-1.1build2_amd64.deb ...\n",
            "Unpacking libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Selecting previously unselected package libxcb-util1:amd64.\n",
            "Preparing to unpack .../13-libxcb-util1_0.4.0-1build2_amd64.deb ...\n",
            "Unpacking libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Selecting previously unselected package libxcb-image0:amd64.\n",
            "Preparing to unpack .../14-libxcb-image0_0.4.0-2_amd64.deb ...\n",
            "Unpacking libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Selecting previously unselected package libxcb-keysyms1:amd64.\n",
            "Preparing to unpack .../15-libxcb-keysyms1_0.4.0-1build3_amd64.deb ...\n",
            "Unpacking libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Selecting previously unselected package libxcb-render-util0:amd64.\n",
            "Preparing to unpack .../16-libxcb-render-util0_0.3.9-1build3_amd64.deb ...\n",
            "Unpacking libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Selecting previously unselected package libxcb-xinerama0:amd64.\n",
            "Preparing to unpack .../17-libxcb-xinerama0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xinput0:amd64.\n",
            "Preparing to unpack .../18-libxcb-xinput0_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxcb-xkb1:amd64.\n",
            "Preparing to unpack .../19-libxcb-xkb1_1.14-3ubuntu3_amd64.deb ...\n",
            "Unpacking libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Selecting previously unselected package libxkbcommon-x11-0:amd64.\n",
            "Preparing to unpack .../20-libxkbcommon-x11-0_1.4.0-1_amd64.deb ...\n",
            "Unpacking libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libqt5gui5:amd64.\n",
            "Preparing to unpack .../21-libqt5gui5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5widgets5:amd64.\n",
            "Preparing to unpack .../22-libqt5widgets5_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package libqt5svg5:amd64.\n",
            "Preparing to unpack .../23-libqt5svg5_5.15.3-1_amd64.deb ...\n",
            "Unpacking libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Selecting previously unselected package libatspi2.0-0:amd64.\n",
            "Preparing to unpack .../24-libatspi2.0-0_2.44.0-3_amd64.deb ...\n",
            "Unpacking libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Selecting previously unselected package libxtst6:amd64.\n",
            "Preparing to unpack .../25-libxtst6_2%3a1.2.3-1build4_amd64.deb ...\n",
            "Unpacking libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Selecting previously unselected package session-migration.\n",
            "Preparing to unpack .../26-session-migration_0.3.6_amd64.deb ...\n",
            "Unpacking session-migration (0.3.6) ...\n",
            "Selecting previously unselected package gsettings-desktop-schemas.\n",
            "Preparing to unpack .../27-gsettings-desktop-schemas_42.0-1ubuntu1_all.deb ...\n",
            "Unpacking gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Selecting previously unselected package at-spi2-core.\n",
            "Preparing to unpack .../28-at-spi2-core_2.44.0-3_amd64.deb ...\n",
            "Unpacking at-spi2-core (2.44.0-3) ...\n",
            "Selecting previously unselected package fluid-soundfont-gm.\n",
            "Preparing to unpack .../29-fluid-soundfont-gm_3.1-5.3_all.deb ...\n",
            "Unpacking fluid-soundfont-gm (3.1-5.3) ...\n",
            "Selecting previously unselected package libinstpatch-1.0-2:amd64.\n",
            "Preparing to unpack .../30-libinstpatch-1.0-2_1.1.6-1_amd64.deb ...\n",
            "Unpacking libinstpatch-1.0-2:amd64 (1.1.6-1) ...\n",
            "Selecting previously unselected package timgm6mb-soundfont.\n",
            "Preparing to unpack .../31-timgm6mb-soundfont_1.3-5_all.deb ...\n",
            "Unpacking timgm6mb-soundfont (1.3-5) ...\n",
            "Selecting previously unselected package libfluidsynth3:amd64.\n",
            "Preparing to unpack .../32-libfluidsynth3_2.2.5-1_amd64.deb ...\n",
            "Unpacking libfluidsynth3:amd64 (2.2.5-1) ...\n",
            "Selecting previously unselected package fluidsynth.\n",
            "Preparing to unpack .../33-fluidsynth_2.2.5-1_amd64.deb ...\n",
            "Unpacking fluidsynth (2.2.5-1) ...\n",
            "Selecting previously unselected package libatk1.0-data.\n",
            "Preparing to unpack .../34-libatk1.0-data_2.36.0-3build1_all.deb ...\n",
            "Unpacking libatk1.0-data (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk1.0-0:amd64.\n",
            "Preparing to unpack .../35-libatk1.0-0_2.36.0-3build1_amd64.deb ...\n",
            "Unpacking libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Selecting previously unselected package libatk-bridge2.0-0:amd64.\n",
            "Preparing to unpack .../36-libatk-bridge2.0-0_2.38.0-3_amd64.deb ...\n",
            "Unpacking libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Selecting previously unselected package libxcomposite1:amd64.\n",
            "Preparing to unpack .../37-libxcomposite1_1%3a0.4.5-1build2_amd64.deb ...\n",
            "Unpacking libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Selecting previously unselected package libgtk-3-common.\n",
            "Preparing to unpack .../38-libgtk-3-common_3.24.33-1ubuntu2.2_all.deb ...\n",
            "Unpacking libgtk-3-common (3.24.33-1ubuntu2.2) ...\n",
            "Selecting previously unselected package libgtk-3-0:amd64.\n",
            "Preparing to unpack .../39-libgtk-3-0_3.24.33-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking libgtk-3-0:amd64 (3.24.33-1ubuntu2.2) ...\n",
            "Selecting previously unselected package libgtk-3-bin.\n",
            "Preparing to unpack .../40-libgtk-3-bin_3.24.33-1ubuntu2.2_amd64.deb ...\n",
            "Unpacking libgtk-3-bin (3.24.33-1ubuntu2.2) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../41-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Selecting previously unselected package libwacom-bin.\n",
            "Preparing to unpack .../42-libwacom-bin_2.2.0-1_amd64.deb ...\n",
            "Unpacking libwacom-bin (2.2.0-1) ...\n",
            "Selecting previously unselected package qsynth.\n",
            "Preparing to unpack .../43-qsynth_0.9.6-1_amd64.deb ...\n",
            "Unpacking qsynth (0.9.6-1) ...\n",
            "Selecting previously unselected package qt5-gtk-platformtheme:amd64.\n",
            "Preparing to unpack .../44-qt5-gtk-platformtheme_5.15.3+dfsg-2ubuntu0.2_amd64.deb ...\n",
            "Unpacking qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Selecting previously unselected package qttranslations5-l10n.\n",
            "Preparing to unpack .../45-qttranslations5-l10n_5.15.3-1_all.deb ...\n",
            "Unpacking qttranslations5-l10n (5.15.3-1) ...\n",
            "Setting up session-migration (0.3.6) ...\n",
            "Created symlink /etc/systemd/user/graphical-session-pre.target.wants/session-migration.service → /usr/lib/systemd/user/session-migration.service.\n",
            "Setting up libdouble-conversion3:amd64 (3.1.7-4) ...\n",
            "Setting up libxcb-xinput0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxtst6:amd64 (2:1.2.3-1build4) ...\n",
            "Setting up libxcb-keysyms1:amd64 (0.4.0-1build3) ...\n",
            "Setting up libxcb-render-util0:amd64 (0.3.9-1build3) ...\n",
            "Setting up libxcb-icccm4:amd64 (0.4.1-1.1build2) ...\n",
            "Setting up libatspi2.0-0:amd64 (2.44.0-3) ...\n",
            "Setting up libxcb-util1:amd64 (0.4.0-1build2) ...\n",
            "Setting up libxcb-xkb1:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up libxcb-image0:amd64 (0.4.0-2) ...\n",
            "Setting up libxcb-xinerama0:amd64 (1.14-3ubuntu3) ...\n",
            "Setting up qttranslations5-l10n (5.15.3-1) ...\n",
            "Setting up libxkbcommon-x11-0:amd64 (1.4.0-1) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libqt5core5a:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libmtdev1:amd64 (1.1.6-1build4) ...\n",
            "Setting up libatk1.0-data (2.36.0-3build1) ...\n",
            "Setting up libqt5dbus5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libmd4c0:amd64 (0.4.8-1) ...\n",
            "Setting up fluid-soundfont-gm (3.1-5.3) ...\n",
            "update-alternatives: using /usr/share/sounds/sf2/FluidR3_GM.sf2 to provide /usr/share/sounds/sf2/default-GM.sf2 (default-GM.sf2) in auto mode\n",
            "update-alternatives: using /usr/share/sounds/sf2/FluidR3_GM.sf2 to provide /usr/share/sounds/sf3/default-GM.sf3 (default-GM.sf3) in auto mode\n",
            "Setting up libatk1.0-0:amd64 (2.36.0-3build1) ...\n",
            "Setting up timgm6mb-soundfont (1.3-5) ...\n",
            "Setting up libxcomposite1:amd64 (1:0.4.5-1build2) ...\n",
            "Setting up libevdev2:amd64 (1.12.1+dfsg-1) ...\n",
            "Setting up libinstpatch-1.0-2:amd64 (1.1.6-1) ...\n",
            "Setting up libgudev-1.0-0:amd64 (1:237-2build1) ...\n",
            "Setting up libgtk-3-common (3.24.33-1ubuntu2.2) ...\n",
            "Setting up libfluidsynth3:amd64 (2.2.5-1) ...\n",
            "Setting up libwacom-common (2.2.0-1) ...\n",
            "Setting up gsettings-desktop-schemas (42.0-1ubuntu1) ...\n",
            "Setting up libwacom9:amd64 (2.2.0-1) ...\n",
            "Setting up libqt5network5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libinput-bin (1.20.0-1ubuntu0.3) ...\n",
            "Setting up libatk-bridge2.0-0:amd64 (2.38.0-3) ...\n",
            "Setting up fluidsynth (2.2.5-1) ...\n",
            "Created symlink /etc/systemd/user/default.target.wants/fluidsynth.service → /usr/lib/systemd/user/fluidsynth.service.\n",
            "Setting up libwacom-bin (2.2.0-1) ...\n",
            "Setting up libinput10:amd64 (1.20.0-1ubuntu0.3) ...\n",
            "Setting up libqt5gui5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5widgets5:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up libqt5svg5:amd64 (5.15.3-1) ...\n",
            "Setting up qsynth (0.9.6-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.4) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for libglib2.0-0:amd64 (2.72.4-0ubuntu2.6) ...\n",
            "Setting up libgtk-3-0:amd64 (3.24.33-1ubuntu2.2) ...\n",
            "Setting up libgtk-3-bin (3.24.33-1ubuntu2.2) ...\n",
            "Setting up qt5-gtk-platformtheme:amd64 (5.15.3+dfsg-2ubuntu0.2) ...\n",
            "Setting up at-spi2-core (2.44.0-3) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt install fluidsynth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/jthickstun/anticipation.git\n",
        "!pip install ./anticipation\n",
        "!pip install -r anticipation/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GwGwz9OqwX0N",
        "outputId": "d4db0942-41a9-4e88-95b9-4c04f337e37c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'anticipation'...\n",
            "remote: Enumerating objects: 1526, done.\u001b[K\n",
            "remote: Counting objects: 100% (318/318), done.\u001b[K\n",
            "remote: Compressing objects: 100% (113/113), done.\u001b[K\n",
            "remote: Total 1526 (delta 253), reused 244 (delta 205), pack-reused 1208 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1526/1526), 56.24 MiB | 27.06 MiB/s, done.\n",
            "Resolving deltas: 100% (1010/1010), done.\n",
            "Processing ./anticipation\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: anticipation\n",
            "  Building wheel for anticipation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for anticipation: filename=anticipation-1.0-py3-none-any.whl size=18682 sha256=06d47d8ea91e35e052623ae6c4404021051e28c758b3bd32c2c0bad1980d9bba\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-azskgnzy/wheels/00/47/a1/fce9dedfd7d5c624e471dc01096a22fd7c945799cf58510c11\n",
            "Successfully built anticipation\n",
            "Installing collected packages: anticipation\n",
            "Successfully installed anticipation-1.0\n",
            "Collecting matplotlib==3.7.1 (from -r anticipation/requirements.txt (line 1))\n",
            "  Downloading matplotlib-3.7.1.tar.gz (38.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting midi2audio==0.1.1 (from -r anticipation/requirements.txt (line 2))\n",
            "  Downloading midi2audio-0.1.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting mido==1.2.10 (from -r anticipation/requirements.txt (line 3))\n",
            "  Downloading mido-1.2.10-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.12/dist-packages (from -r anticipation/requirements.txt (line 4)) (2.0.2)\n",
            "Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.12/dist-packages (from -r anticipation/requirements.txt (line 5)) (2.8.0+cu126)\n",
            "Collecting transformers==4.29.2 (from -r anticipation/requirements.txt (line 6))\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl.metadata (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.65.0 (from -r anticipation/requirements.txt (line 7))\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl.metadata (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (0.36.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (2.32.4)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.29.2->-r anticipation/requirements.txt (line 6))\n",
            "  Downloading tokenizers-0.13.3.tar.gz (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.9/314.9 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (3.4.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib==3.7.1->-r anticipation/requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.1->-r anticipation/requirements.txt (line 5)) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers==4.29.2->-r anticipation/requirements.txt (line 6)) (2025.10.5)\n",
            "Downloading midi2audio-0.1.1-py2.py3-none-any.whl (8.7 kB)\n",
            "Downloading mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m96.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: matplotlib, tokenizers\n",
            "  Building wheel for matplotlib (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for matplotlib: filename=matplotlib-3.7.1-cp312-cp312-linux_x86_64.whl size=11092788 sha256=4a4fd133658d1849e53c79d30bd65f95fe4a6be72434fbb742b6eac5ce2b1524\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/06/fa/3453aac11411fac092c1bdfe52815f2f6969a42700d977e62f\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mBuilding wheel for tokenizers \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully built matplotlib\n",
            "Failed to build tokenizers\n",
            "\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (tokenizers)\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tokenizers\n",
        "!pip install \"midi2audio==0.1.1\"\n",
        "!pip install \"mido==1.2.10\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QGi84UEwYi-",
        "outputId": "92f1d20c-f95b-459d-a013-64e98f5b2a12"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.12/dist-packages (0.22.1)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.16.4 in /usr/local/lib/python3.12/dist-packages (from tokenizers) (0.36.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.16.4->tokenizers) (1.2.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub<2.0,>=0.16.4->tokenizers) (2025.10.5)\n",
            "Collecting midi2audio==0.1.1\n",
            "  Using cached midi2audio-0.1.1-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Using cached midi2audio-0.1.1-py2.py3-none-any.whl (8.7 kB)\n",
            "Installing collected packages: midi2audio\n",
            "Successfully installed midi2audio-0.1.1\n",
            "Collecting mido==1.2.10\n",
            "  Using cached mido-1.2.10-py2.py3-none-any.whl.metadata (3.4 kB)\n",
            "Using cached mido-1.2.10-py2.py3-none-any.whl (51 kB)\n",
            "Installing collected packages: mido\n",
            "Successfully installed mido-1.2.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup the runtime environment"
      ],
      "metadata": {
        "id": "9uFcdhHNwjMq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys,time\n",
        "\n",
        "import midi2audio\n",
        "import transformers\n",
        "from transformers import AutoModelForCausalLM\n",
        "\n",
        "from IPython.display import Audio\n",
        "\n",
        "from anticipation import ops\n",
        "from anticipation.sample import generate\n",
        "from anticipation.tokenize import extract_instruments\n",
        "from anticipation.convert import events_to_midi,midi_to_events\n",
        "from anticipation.visuals import visualize\n",
        "from anticipation.config import *\n",
        "from anticipation.vocab import *"
      ],
      "metadata": {
        "id": "ZUxt5IPUwaZZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SMALL_MODEL = 'stanford-crfm/music-small-800k'     # faster inference, worse sample quality\n",
        "MEDIUM_MODEL = 'stanford-crfm/music-medium-800k'   # slower inference, better sample quality\n",
        "LARGE_MODEL = 'stanford-crfm/music-large-800k'     # slowest inference, best sample quality\n",
        "\n",
        "# load an anticipatory music transformer\n",
        "model = AutoModelForCausalLM.from_pretrained(SMALL_MODEL).cuda()\n",
        "\n",
        "# a MIDI synthesizer\n",
        "fs = midi2audio.FluidSynth('/usr/share/sounds/sf2/FluidR3_GM.sf2')\n",
        "\n",
        "# the MIDI synthesis script\n",
        "def synthesize(fs, tokens):\n",
        "    mid = events_to_midi(tokens)\n",
        "    mid.save('tmp.mid')\n",
        "    fs.midi_to_audio('tmp.mid', 'tmp.wav')\n",
        "    return 'tmp.wav'"
      ],
      "metadata": {
        "id": "vjN4AZiLwlK2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208,
          "referenced_widgets": [
            "239e6c9da6b84c339b886ea3ba2b688b",
            "b5ef4f7e3b4a4ad8b683ec82ab5934e9",
            "54efff78409942c4b309c1767449d00c",
            "1c1cfc594e54410799230fbc7ae12d31",
            "56691a60939f4684b79851559d33a046",
            "76d174a2409a4889ae28f2229cfacfa7",
            "bfbf095cf7ec4cd38d4ae8bf40bd41bd",
            "d9b1cb2b903244b6833506250ee55781",
            "f1770bbf0dd24175a91e757c3865b119",
            "83c7c6a32b314c278946586c5dfb0a70",
            "ce585cfad938467db0d1588bcc4ffcd1",
            "bf91d66a181c46d6be656a7067b35a0e",
            "5b4a5621f88e4a6081c2cc7664163eb0",
            "1883c5c23e3541f79d930ee7bf95dfa2",
            "f0dd59d320224ea8af9177fc3ff80e86",
            "656374c70bd94627b0cc0d246d6d83f1",
            "eeb7c52eee074840abd144b413178878",
            "314dc1cbbbc74f8c9fc1da70587e5ae5",
            "7975553ce48f45e5979e6e0e602009c8",
            "59cb41c119f44027aa8cb507f4246c52",
            "ddc77745f5154e10a3dbee6ed700b285",
            "fd9060dee584487dbdefce8dff94549c"
          ]
        },
        "outputId": "55187aa1-2428-4a30-d559-29ad6f4dd955"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "239e6c9da6b84c339b886ea3ba2b688b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/512M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf91d66a181c46d6be656a7067b35a0e"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from anticipation import ops\n",
        "from anticipation.config import *\n",
        "from anticipation.vocab import *"
      ],
      "metadata": {
        "id": "kS5AlDAWwqtu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Custom functions"
      ],
      "metadata": {
        "id": "qmpa4Gq3wsnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_logits(logits, idx):\n",
        "    logits[CONTROL_OFFSET:SPECIAL_OFFSET] = -float('inf') # don't generate controls\n",
        "    logits[SPECIAL_OFFSET:] = -float('inf')               # don't generate special tokens\n",
        "\n",
        "    # don't generate stuff in the wrong time slot\n",
        "    if idx % 3 == 0:\n",
        "        logits[DUR_OFFSET:DUR_OFFSET+MAX_DUR] = -float('inf')\n",
        "        logits[NOTE_OFFSET:NOTE_OFFSET+MAX_NOTE] = -float('inf')\n",
        "    elif idx % 3 == 1:\n",
        "        logits[TIME_OFFSET:TIME_OFFSET+MAX_TIME] = -float('inf')\n",
        "        logits[NOTE_OFFSET:NOTE_OFFSET+MAX_NOTE] = -float('inf')\n",
        "    elif idx % 3 == 2: #expecting a note token\n",
        "        logits[TIME_OFFSET:TIME_OFFSET+MAX_TIME] = -float('inf')\n",
        "        logits[DUR_OFFSET:DUR_OFFSET+MAX_DUR] = -float('inf')\n",
        "\n",
        "    return logits\n",
        "\n",
        "\n",
        "def nucleus(logits, top_p):\n",
        "    # from HF implementation\n",
        "    if top_p < 1.0:\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "        # Remove tokens with cumulative probability above the threshold (token with 0 are kept)\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "\n",
        "        # Shift the indices to the right to keep also the first token above the threshold\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "        # scatter sorted tensors to original indexing\n",
        "        indices_to_remove = sorted_indices_to_remove.scatter(0, sorted_indices, sorted_indices_to_remove)\n",
        "        logits[indices_to_remove] = -float(\"inf\")\n",
        "\n",
        "    return logits\n",
        "\n",
        "\n",
        "def future_logits(logits, curtime):\n",
        "    \"\"\" don't sample events in the past \"\"\"\n",
        "    if curtime > 0:\n",
        "        logits[TIME_OFFSET:TIME_OFFSET+curtime] = -float('inf')\n",
        "\n",
        "    return logits\n",
        "\n",
        "\n",
        "def instr_logits_part1(logits, full_history, instruments):\n",
        "    \"\"\" don't sample more than 16 instruments \"\"\"\n",
        "    instrs = ops.get_instruments(full_history)\n",
        "    print(\"instruments full history\", instrs)\n",
        "\n",
        "    if instruments is not None:\n",
        "    #ONLY ALLOW SPECIFIED INSTRUMENTS, BE CAREFUL -- which instruments are present in full_history?\n",
        "        #print(\"ONLY ALLOW SPECIFIED INSTRUMENTS\")\n",
        "        for instr_id in range(128):\n",
        "            if instr_id not in instruments:\n",
        "                #print(\"block instrument\", instr_id)\n",
        "                logits[NOTE_OFFSET+instr_id*MAX_PITCH:NOTE_OFFSET+(instr_id+1)*MAX_PITCH] = -float('inf')\n",
        "            else:\n",
        "                print(\"allowed instruemtn\", instr_id)\n",
        "\n",
        "    if len(instrs) < 15: # 16 - 1 to account for the reserved drum track\n",
        "        return logits\n",
        "\n",
        "    for instr in range(MAX_INSTR):\n",
        "        if instr not in instrs: #only use instruments in instrs, which i guess means from full_history it should be instruments used in the past\n",
        "            logits[NOTE_OFFSET+instr*MAX_PITCH:NOTE_OFFSET+(instr+1)*MAX_PITCH] = -float('inf')\n",
        "\n",
        "\n",
        "    return logits\n",
        "\n",
        "\n",
        "def add_token_part1(model, z, tokens, top_p, current_time, instruments, debug=False):\n",
        "    assert len(tokens) % 3 == 0\n",
        "\n",
        "    history = tokens.copy()\n",
        "    lookback = max(len(tokens) - 1017, 0)\n",
        "    history = history[lookback:] # Markov window\n",
        "    offset = ops.min_time(history, seconds=False)\n",
        "    history[::3] = [tok - offset for tok in history[::3]] # relativize time in the history buffer\n",
        "\n",
        "    new_token = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(3):\n",
        "            input_tokens = torch.tensor(z + history + new_token).unsqueeze(0).to(model.device)\n",
        "            logits = model(input_tokens).logits[0,-1]\n",
        "\n",
        "            idx = input_tokens.shape[1]-1\n",
        "            logits = safe_logits(logits, idx)\n",
        "            if i == 0:\n",
        "                logits = future_logits(logits, current_time - offset)\n",
        "            elif i == 2:\n",
        "                logits = instr_logits_part1(logits, tokens, instruments) #PASS DOWN THE RESTRICTION HERE\n",
        "            logits = nucleus(logits, top_p)\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            token = torch.multinomial(probs, 1)\n",
        "            new_token.append(int(token))\n",
        "\n",
        "    new_token[0] += offset # revert to full sequence timing\n",
        "    if debug:\n",
        "        print(f'  OFFSET = {offset}, LEN = {len(history)}, TIME = {tokens[::3][-5:]}')\n",
        "    print(\"new token: \", new_token[0], new_token[1], new_token[2])\n",
        "\n",
        "    return new_token\n"
      ],
      "metadata": {
        "id": "qgP60slpxTdU"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataclasses import dataclass, field\n",
        "from math import inf\n",
        "from typing import Optional, List\n",
        "\n",
        "@dataclass\n",
        "class Beam:\n",
        "    tokens: List[int]                  #full token history (context + generated)\n",
        "    score: float = 0.0                 #sum of log-probs for generated tokens\n",
        "    current_time: float = 0.0          #last generated absolute TIME (after offset)\n",
        "    control_tokens: List[int] = field(default_factory=list)  #put controls per-beam rather than global in case times don't align\n",
        "    anticip_time: float = inf          #onset of next anticipatory triple (ATIME - ATIME_OFFSET)\n",
        "    gen_len: int = 0\n",
        "    constraint_tracker: Optional[int] = None"
      ],
      "metadata": {
        "id": "jhNyKP5DxcWk"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def safe_logits(logits, idx):\n",
        "    logits[CONTROL_OFFSET:SPECIAL_OFFSET] = -float('inf') # don't generate controls\n",
        "    logits[SPECIAL_OFFSET:] = -float('inf')               # don't generate special tokens\n",
        "\n",
        "    # don't generate stuff in the wrong time slot\n",
        "    if idx % 3 == 0:\n",
        "        logits[DUR_OFFSET:DUR_OFFSET+MAX_DUR] = -float('inf')\n",
        "        logits[NOTE_OFFSET:NOTE_OFFSET+MAX_NOTE] = -float('inf')\n",
        "    elif idx % 3 == 1:\n",
        "        logits[TIME_OFFSET:TIME_OFFSET+MAX_TIME] = -float('inf')\n",
        "        logits[NOTE_OFFSET:NOTE_OFFSET+MAX_NOTE] = -float('inf')\n",
        "    elif idx % 3 == 2: #expecting a note token\n",
        "        logits[TIME_OFFSET:TIME_OFFSET+MAX_TIME] = -float('inf')\n",
        "        logits[DUR_OFFSET:DUR_OFFSET+MAX_DUR] = -float('inf')\n",
        "\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "szXDxXnbxgw2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def nucleus(logits, top_p):\n",
        "    # from HF implementation\n",
        "    if top_p < 1.0:\n",
        "        sorted_logits, sorted_indices = torch.sort(logits, descending=True)\n",
        "        cumulative_probs = torch.cumsum(F.softmax(sorted_logits, dim=-1), dim=-1)\n",
        "\n",
        "        # Remove tokens with cumulative probability above the threshold (token with 0 are kept)\n",
        "        sorted_indices_to_remove = cumulative_probs > top_p\n",
        "\n",
        "        # Shift the indices to the right to keep also the first token above the threshold\n",
        "        sorted_indices_to_remove[..., 1:] = sorted_indices_to_remove[..., :-1].clone()\n",
        "        sorted_indices_to_remove[..., 0] = 0\n",
        "\n",
        "        # scatter sorted tensors to original indexing\n",
        "        indices_to_remove = sorted_indices_to_remove.scatter(0, sorted_indices, sorted_indices_to_remove)\n",
        "        logits[indices_to_remove] = -float(\"inf\")\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "j0bdsgBcxird"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def future_logits(logits, curtime):\n",
        "    \"\"\" don't sample events in the past \"\"\"\n",
        "    if curtime > 0:\n",
        "        logits[TIME_OFFSET:TIME_OFFSET+curtime+1] = -float('inf')\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "mL3aWrChxlNw"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def instr_logits_part1(logits, full_history, instruments):\n",
        "    \"\"\" don't sample more than 16 instruments \"\"\"\n",
        "    instrs = ops.get_instruments(full_history)\n",
        "    #print(\"instruments full history\", instrs)\n",
        "\n",
        "    if instruments is not None:\n",
        "    #ONLY ALLOW SPECIFIED INSTRUMENTS, BE CAREFUL -- which instruments are present in full_history?\n",
        "        #print(\"ONLY ALLOW SPECIFIED INSTRUMENTS\")\n",
        "        for instr_id in range(129): #INCLUDE DRUMS AS SOMETHING WHICH CAN BE BLOCKED\n",
        "            if instr_id not in instruments:\n",
        "                #print(\"block instrument\", instr_id)\n",
        "                logits[NOTE_OFFSET+instr_id*MAX_PITCH:NOTE_OFFSET+(instr_id+1)*MAX_PITCH] = -float('inf')\n",
        "            #else:\n",
        "                #print(\"allowed instruemtn\", instr_id)\n",
        "\n",
        "    if len(instrs) < 15: # 16 - 1 to account for the reserved drum track\n",
        "        return logits\n",
        "\n",
        "    for instr in range(MAX_INSTR):\n",
        "        if instr not in instrs: #only use instruments in instrs, which i guess means from full_history it should be instruments used in the past\n",
        "            logits[NOTE_OFFSET+instr*MAX_PITCH:NOTE_OFFSET+(instr+1)*MAX_PITCH] = -float('inf')\n",
        "\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "fsXKxoYKxnnQ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_token_part1_modified(model, z, tokens, top_p, current_time, instruments, debug=False):\n",
        "    assert len(tokens) % 3 == 0\n",
        "\n",
        "    history = tokens.copy()\n",
        "    lookback = max(len(tokens) - 1017, 0)\n",
        "    history = history[lookback:] # Markov window\n",
        "    offset = ops.min_time(history, seconds=False)\n",
        "    history[::3] = [tok - offset for tok in history[::3]] # relativize time in the history buffer\n",
        "\n",
        "    new_token = []\n",
        "    new_token_score = 0\n",
        "    with torch.no_grad():\n",
        "        for i in range(3):\n",
        "            input_tokens = torch.tensor(z + history + new_token).unsqueeze(0).to(model.device)\n",
        "            logits = model(input_tokens).logits[0,-1]\n",
        "\n",
        "            idx = input_tokens.shape[1]-1\n",
        "            logits = safe_logits(logits, idx)\n",
        "            if i == 0:\n",
        "                logits = future_logits(logits, current_time - offset)\n",
        "            elif i == 2:\n",
        "                logits = instr_logits_part1(logits, tokens, instruments) #PASS DOWN THE RESTRICTION HERE\n",
        "            logits = nucleus(logits, top_p)\n",
        "\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            log_probs = F.log_softmax(logits, dim=-1)\n",
        "            token = torch.multinomial(probs, 1)\n",
        "            new_token.append(int(token))\n",
        "            new_token_score += float(log_probs[int(token)].item())\n",
        "\n",
        "    new_token[0] += offset # revert to full sequence timing\n",
        "    if debug:\n",
        "        print(f'  OFFSET = {offset}, LEN = {len(history)}, TIME = {tokens[::3][-5:]}')\n",
        "    print(\"new token: \", new_token[0], new_token[1], new_token[2], \"score: \", new_token_score)\n",
        "\n",
        "    return new_token, new_token_score"
      ],
      "metadata": {
        "id": "OMt2-eC0Ciyb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topk_triples(model, z, tokens, current_time, instruments, debug=False, K_time=4, K_dur=2, K_note=2, K_total=8, top_p=None):\n",
        "    assert len(tokens) % 3 == 0\n",
        "\n",
        "    device=model.device\n",
        "\n",
        "    history = tokens.copy()\n",
        "    lookback = max(len(tokens) - 1017, 0)\n",
        "    history = history[lookback:] # Markov window\n",
        "    offset = ops.min_time(history, seconds=False)\n",
        "    history[::3] = [tok - offset for tok in history[::3]] # relativize time in the history buffer\n",
        "\n",
        "    def apply_masks(logits, phase_idx, inp_len, tokens): #uhhh compared to original code inp_len is basically input_tokens.shape[1]\n",
        "        logits = safe_logits(logits, inp_len - 1)\n",
        "        if phase_idx == 0:\n",
        "            logits = future_logits(logits, current_time - offset)\n",
        "        elif phase_idx == 2:\n",
        "            logits = instr_logits_part1(logits, tokens, instruments)\n",
        "        if top_p is not None:\n",
        "            logits = nucleus(logits, top_p)\n",
        "        return logits\n",
        "\n",
        "    with torch.no_grad():\n",
        "        #TIME TOKEN: generate K_time possibilities\n",
        "        inp0 = torch.tensor(z + history, device=device).unsqueeze(0)\n",
        "        logits_t = model(inp0).logits[0, -1] #(1, L, V) -> just shape V\n",
        "        logits_t = apply_masks(logits_t, phase_idx=0, inp_len=inp0.shape[1], tokens=tokens)\n",
        "        logp_t = torch.log_softmax(logits_t, dim=-1)\n",
        "        t_vals, t_ids = torch.topk(logp_t, K_time)\n",
        "        t_ids = t_ids.tolist(); t_vals = t_vals.tolist()\n",
        "\n",
        "        #DURATION TOKEN (batch over K_time)\n",
        "        #build batch prefixes: z + history + [t_i]\n",
        "        batch_time_inputs = [z + history + [t] for t in t_ids]\n",
        "        inp1 = torch.nn.utils.rnn.pad_sequence(\n",
        "            [torch.tensor(x, device=device) for x in batch_time_inputs],\n",
        "            batch_first=True\n",
        "        )\n",
        "        logits_d_all = model(inp1).logits[:, -1, :] #[K_time, L, V] -> [K_time, V]\n",
        "        logp_d_all = []\n",
        "        d_ids_all  = []\n",
        "        for row, base_len in zip(logits_d_all, [len(x) for x in batch_time_inputs]):\n",
        "            row = apply_masks(row, phase_idx=1, inp_len=base_len, tokens=tokens)\n",
        "            #note tokens is the \"old\" full history but it's ok here, the only thing apply_masks\n",
        "            #passes it into is instr_logit which cares about instrument history we're chilling\n",
        "            lp = torch.log_softmax(row, dim=-1)\n",
        "            d_vals, d_ids = torch.topk(lp, K_dur) #take top K_dur options\n",
        "            logp_d_all.append(d_vals)\n",
        "            d_ids_all.append(d_ids)\n",
        "        #shapes end up being lists of K_time tensors, each [K_dur]\n",
        "\n",
        "        #NOTE TOKEN (batch over K_time *K_dur)\n",
        "        td_pairs = []\n",
        "        td_logps = []\n",
        "        td_inputs = []\n",
        "        for i in range(len(t_ids)): #K_time outer loop\n",
        "            for j in range(K_dur): #K_dur inner loop\n",
        "                time_token_id = t_ids[i] #token id\n",
        "                lp_time = t_vals[i] #log prob for that token\n",
        "                dur_token_id = d_ids_all[i][j].item()\n",
        "                lp_dur = logp_d_all[i][j].item()\n",
        "                td_pairs.append((time_token_id, dur_token_id, lp_time, lp_dur))\n",
        "                td_inputs.append(z + history + [time_token_id, dur_token_id])\n",
        "\n",
        "        inp2 = torch.nn.utils.rnn.pad_sequence( #batched processing (K_time*K_dur) batches\n",
        "            [torch.tensor(x, device=device) for x in td_inputs],\n",
        "            batch_first=True\n",
        "        )\n",
        "        logits_n_all = model(inp2).logits[:, -1, :] #(K_time*K_dur, L, V) -> (K_time*K_dur, V)\n",
        "\n",
        "        candidates = []  # (triple_ids, joint_logp)\n",
        "        idx = 0\n",
        "        for i in range(len(t_ids)): #K_time\n",
        "            for j in range(K_dur): #K_dur\n",
        "                row = logits_n_all[idx]\n",
        "                idx += 1 #counts up to K_time*K_dur\n",
        "                base_len = len(td_inputs[i*K_dur + j])\n",
        "                row = apply_masks(row, phase_idx=2, inp_len=base_len, tokens=tokens)\n",
        "                lp = torch.log_softmax(row, dim=-1)\n",
        "                note_vals, note_ids = torch.topk(lp, K_note) #pick top K_note options\n",
        "                time_token_id, dur_token_id, lp_time, lp_dur = td_pairs[i*K_dur + j]\n",
        "                for k in range(K_note):\n",
        "                    note_token_id = note_ids[k].item()\n",
        "                    lp_note = note_vals[k].item()\n",
        "                    joint = lp_time + lp_dur + lp_note\n",
        "                    candidates.append(([time_token_id, dur_token_id, note_token_id], joint))\n",
        "\n",
        "        def dedup(candidates):\n",
        "            unique = {}\n",
        "            for note_choice, logprob in candidates:\n",
        "                key = tuple(note_choice)\n",
        "                if key not in unique or logprob > unique[key]:\n",
        "                    unique[key] = logprob #tuplify the array of 3\n",
        "            return [(list(key), unique[key]) for key in unique.keys()]\n",
        "\n",
        "        candidates = dedup(candidates) #remove duplicates hopefully this helps\n",
        "\n",
        "        #candidates has list of triples ([time token, dur token, note token], prob)\n",
        "        joint_logps = torch.tensor([logprob for _, logprob in candidates], device=device)\n",
        "        #gumbel top k sampling, basically the idea is you add random noise before you take the top k\n",
        "        u = torch.rand_like(joint_logps)\n",
        "        g = -torch.log(-torch.log(u))              # Gumbel(0,1)\n",
        "        tau = 1.0                                  # temperature: 1.0–1.5 = good range\n",
        "        scores = joint_logps / tau + g             # random jittered scores\n",
        "\n",
        "        #choose K_total without replacement (highest noised scores)\n",
        "        top = torch.topk(scores, K_total)\n",
        "        best = [candidates[i] for i in top.indices.tolist()]\n",
        "\n",
        "        #ALTERNATIVELY, DETERMINISTIC TOP TOTAL_K -> tried this and it led to beam collapse\n",
        "        #candidates.sort(key=lambda x: x[1], reverse=True) #highest to lowest by joint prob\n",
        "        #best = candidates[:K_total]\n",
        "\n",
        "        triples = torch.tensor([ids for ids,_ in best], device=device, dtype=torch.long)  # [K_total, 3]\n",
        "        logps  = torch.tensor([lp  for _,lp in best], device=device, dtype=torch.float)   # [K_total]\n",
        "\n",
        "    #if TIME in history was relativized by `offset`, undo for output:\n",
        "    triples[:, 0] = triples[:, 0] + offset\n",
        "    print(\"triple of tokens option from single beam\", triples)\n",
        "\n",
        "    return triples, logps #FORMAT IS TENSOR OF SHAPES [K_total, 3] and [K_total]\n"
      ],
      "metadata": {
        "id": "Ioe0Vtg0xrGF"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_beams(model, start_time, end_time, inputs=None, controls=None, top_p=None,\n",
        "                   debug=False, delta=DELTA*TIME_RESOLUTION, instruments=None,\n",
        "                   num_beams=10, K_total=10, K_time=5, K_dur=2, K_note=3):\n",
        "    if inputs is None:\n",
        "        inputs = []\n",
        "\n",
        "    if controls is None:\n",
        "        controls = []\n",
        "\n",
        "    start_time = int(TIME_RESOLUTION*start_time)\n",
        "    end_time = int(TIME_RESOLUTION*end_time)\n",
        "\n",
        "    # prompt is events up to start_time\n",
        "    prompt = ops.pad(ops.clip(inputs, 0, start_time, clip_duration=False, seconds=False), start_time)\n",
        "\n",
        "    # treat events beyond start_time as controls\n",
        "    future = ops.clip(inputs, start_time+1, ops.max_time(inputs, seconds=False), clip_duration=False, seconds=False)\n",
        "    if debug:\n",
        "        print('Future')\n",
        "        ops.print_tokens(future)\n",
        "\n",
        "    # clip controls that preceed the sequence\n",
        "    controls = ops.clip(controls, DELTA, ops.max_time(controls, seconds=False), clip_duration=False, seconds=False)\n",
        "\n",
        "    if debug:\n",
        "        print('Controls')\n",
        "        ops.print_tokens(controls)\n",
        "\n",
        "    z = [ANTICIPATE] if len(controls) > 0 or len(future) > 0 else [AUTOREGRESS]\n",
        "    if debug:\n",
        "        print('AR Mode' if z[0] == AUTOREGRESS else 'AAR Mode')\n",
        "\n",
        "    # interleave the controls with the events\n",
        "    tokens, controls = ops.anticipate(prompt, ops.sort(controls + [CONTROL_OFFSET+token for token in future]))\n",
        "\n",
        "    if debug:\n",
        "        print('Prompt')\n",
        "        ops.print_tokens(tokens)\n",
        "\n",
        "    current_time = ops.max_time(prompt, seconds=False)\n",
        "\n",
        "    if debug:\n",
        "        print('Current time:', current_time)\n",
        "\n",
        "    #ok now we make a list of beams each initializing tokens with the controls\n",
        "    beams = []\n",
        "    for _ in range(num_beams):\n",
        "        beams.append(Beam(\n",
        "          tokens=tokens.copy(),\n",
        "          control_tokens=controls.copy(),\n",
        "          anticip_time=(controls[0] - ATIME_OFFSET if controls else math.inf),\n",
        "          score=0.0,\n",
        "          current_time=current_time,\n",
        "          gen_len = 0\n",
        "        ))\n",
        "\n",
        "    #with tqdm(range(end_time-start_time)) as progress:\n",
        "    not_done = True\n",
        "    counter = -1\n",
        "    phrase = 3\n",
        "\n",
        "    while not_done:\n",
        "\n",
        "        counter += 1\n",
        "        candidates = []\n",
        "        unique_beams = {}\n",
        "        not_done = False\n",
        "\n",
        "        for idx, beam in enumerate(beams): #for every add a token triplet in each one which hasn't finished\n",
        "\n",
        "            #directly add the finished beams\n",
        "            if beam.current_time >= end_time:\n",
        "                candidates.append(beam)\n",
        "                continue\n",
        "\n",
        "            not_done = True #if at least one beam gets token added, then not done\n",
        "            #last pass not_done will be False if every beam is done\n",
        "            print(\"beam\", idx, \"has current time\", beam.current_time, \"tokens\", beam.tokens)\n",
        "            print(\"anticipated_time\", beam.anticip_time, \"end_time\", end_time)\n",
        "\n",
        "            #directly mutate control_tokens, anticip_time\n",
        "            while beam.current_time >= beam.anticip_time - delta:\n",
        "\n",
        "                if not beam.control_tokens:\n",
        "                    break\n",
        "\n",
        "                atime, adur, anote = beam.control_tokens[:3]\n",
        "                beam.tokens.extend([atime, adur, anote])\n",
        "                beam.control_tokens = beam.control_tokens[3:]\n",
        "\n",
        "                if debug:\n",
        "                    note = anote - ANOTE_OFFSET\n",
        "                    instr = note//2**7\n",
        "                    print('A', atime - ATIME_OFFSET, adur - ADUR_OFFSET, instr, note - (2**7)*instr)\n",
        "\n",
        "                if len(beam.control_tokens) > 0:\n",
        "                    beam.anticip_time = beam.control_tokens[0] - ATIME_OFFSET\n",
        "                else:\n",
        "                    beam.anticip_time = math.inf\n",
        "\n",
        "            if counter % phrase != 0: #just generate normally rather than branching on this triplet\n",
        "                new_token, new_token_score = add_token_part1_modified(model, z, beam.tokens, top_p=top_p,\n",
        "                                            current_time=max(start_time, beam.current_time),\n",
        "                                            instruments=instruments, debug=True)\n",
        "                if new_token[0] < end_time: #new token's time\n",
        "                      possible_beam = Beam(\n",
        "                          tokens=beam.tokens.copy() + new_token,\n",
        "                          control_tokens=beam.control_tokens[:],\n",
        "                          anticip_time = beam.anticip_time,\n",
        "                          score=beam.score + new_token_score,\n",
        "                          current_time=new_token[0],\n",
        "                          gen_len = beam.gen_len+3\n",
        "                      )\n",
        "                      candidates.append(possible_beam)\n",
        "                else:\n",
        "                    candidates.append(beam)\n",
        "\n",
        "                continue #don't do the branching\n",
        "\n",
        "            new_triples, logps = topk_triples(model, z, beam.tokens, max(start_time,beam.current_time), instruments=instruments, K_total=K_total,\n",
        "                                              debug=debug, K_time=K_time, K_dur=K_dur, K_note=K_note, top_p=None)\n",
        "            #also has default parameters (debug=False, K_time=4, K_dur=2, K_note=2, K_total=8, top_p=None)\n",
        "            #shapes [K_total, 3] and [K_total]\n",
        "\n",
        "            for row, logp in zip(new_triples, logps):\n",
        "\n",
        "                  new_time = row[0].item() - TIME_OFFSET\n",
        "                  if new_time < beam.current_time:\n",
        "                      continue\n",
        "\n",
        "                  if new_time < end_time:\n",
        "                      possible_beam = Beam(\n",
        "                          tokens=beam.tokens.copy() + [token.item() for token in row],\n",
        "                          control_tokens=beam.control_tokens[:],\n",
        "                          anticip_time = beam.anticip_time,\n",
        "                          score=beam.score + logp.item(),\n",
        "                          current_time=new_time, #the new time, don't actually mutate new_triples\n",
        "                          gen_len = beam.gen_len+3\n",
        "                      )\n",
        "                  else: #DON'T ACTUALLY APPEND THAT TRIPLE, though anticipation has been mutated\n",
        "                      possible_beam = Beam(\n",
        "                          tokens=beam.tokens.copy(),\n",
        "                          control_tokens=beam.control_tokens[:],\n",
        "                          anticip_time = beam.anticip_time,\n",
        "                          score=beam.score,\n",
        "                          current_time=new_time, #terminal beam candidate, kill it from growing to prevent inf loop\n",
        "                          gen_len=beam.gen_len\n",
        "                      )\n",
        "\n",
        "                  if tuple(possible_beam.tokens) not in unique_beams: #DEDUP\n",
        "                      unique_beams[tuple(possible_beam.tokens)] = True\n",
        "                      candidates.append(possible_beam)\n",
        "\n",
        "            if debug:\n",
        "                print(\"print data about the new triples generated?\")\n",
        "                #new_note = new_token[2] - NOTE_OFFSET\n",
        "                #new_instr = new_note//2**7\n",
        "                #new_pitch = new_note - (2**7)*new_instr\n",
        "                #print('C', new_time, new_token[1] - DUR_OFFSET, new_instr, new_pitch)\n",
        "\n",
        "        def rank(b, alpha=0.5, gamma=0.01, empty_penalty=1e6, start_tick=0):\n",
        "            #normalize for length\n",
        "            base = b.score / (max(1, b.gen_len) ** alpha)\n",
        "\n",
        "            #favor beams that advance forward in time\n",
        "            #be careful to scale gamma to your tick units / seconds, start_tick is start_time in ticks\n",
        "            prog = gamma * max(0, b.current_time - start_tick)\n",
        "\n",
        "            #add penalty for empty generations so that we don't just end up with prompt and nothing else\n",
        "            if b.gen_len == 0:\n",
        "                return base + prog - empty_penalty\n",
        "\n",
        "            return base + prog\n",
        "\n",
        "        candidates.sort(key=lambda b: rank(b), reverse=True) #highest to lowest by score, in-place sort\n",
        "        beams = candidates[:num_beams]\n",
        "        # for beam in beams:\n",
        "        #     print(\"current time\", beam.current_time, \"tokens\", beam.tokens)\n",
        "\n",
        "\n",
        "    #NOW CHOOSE FINAl OUTPUT OFF OF BEAMS LIST\n",
        "    if beams:\n",
        "        best_tokens = beams[0].tokens\n",
        "    else:\n",
        "        best_tokens = tokens\n",
        "\n",
        "    print(\"best_tokens\", best_tokens)\n",
        "    events, _ = ops.split(best_tokens)\n",
        "    return ops.sort(ops.unpad(events) + future)"
      ],
      "metadata": {
        "id": "l45q_RqBxtQw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing inference!\n"
      ],
      "metadata": {
        "id": "z_8AuApgxuGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(TIME_OFFSET)\n",
        "print(DUR_OFFSET)\n",
        "print(NOTE_OFFSET)\n",
        "print(ATIME_OFFSET)\n",
        "print(ADUR_OFFSET)\n",
        "print(ANOTE_OFFSET)\n",
        "print(CONTROL_OFFSET)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl9K8c9TwKnh",
        "outputId": "4f8579e6-e9e3-472d-c16f-c46b0f043fb5"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "10000\n",
            "11000\n",
            "27513\n",
            "37513\n",
            "38513\n",
            "27513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "music_before = [0, 10001, 11190, 40, 10001, 11178, 80, 10001, 11159, 180, 10001, 11164, 220, 10004, 11194, 260, 10004, 11158,\n",
        "                400, 10002, 11190, 410, 10040, 11178, 420, 10040, 11159, 440, 10040, 11164, 460, 10040, 11194]\n",
        "coplayer = [800, 10010, 11164, 800, 10010, 11168, 800, 10010, 11171]"
      ],
      "metadata": {
        "id": "ZUqFY-qengZ6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tokens= generate_beams(model, start_time=5, end_time=10, inputs=music_before, controls=coplayer, top_p=.98, instruments={1, 2, 3, 4}, debug=False,\n",
        "                              num_beams=10, K_total=10, K_time=5, K_dur=2, K_note=5) #K_total is branch factor\n",
        "Audio(synthesize(fs, sample_tokens))"
      ],
      "metadata": {
        "id": "RoWtQY7OxvEb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "769da965-35f2-43ac-ae32-9af330b04212"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beam 0 has current time 460 tokens [800, 10010, 11164, 800, 10010, 11168, 800, 10010, 11171, 0, 10001, 11190, 40, 10001, 11178, 80, 10001, 11159, 180, 10001, 11164, 220, 10004, 11194, 260, 10004, 11158, 360, 10000, 27512, 400, 10002, 11190, 410, 10040, 11178, 420, 10040, 11159, 440, 10040, 11164, 460, 10040, 11194]\n",
            "anticipated_time inf end_time 1000\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AcceleratorError",
          "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAcceleratorError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-95547756.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sample_tokens= generate_beams(model, start_time=5, end_time=10, inputs=music_before, controls=coplayer, top_p=.98, instruments={1, 2, 3, 4}, debug=False,\n\u001b[0m\u001b[1;32m      2\u001b[0m                               num_beams=10, K_total=10, K_time=5, K_dur=2, K_note=5) #K_total is branch factor\n\u001b[1;32m      3\u001b[0m \u001b[0mAudio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msynthesize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_tokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2906791094.py\u001b[0m in \u001b[0;36mgenerate_beams\u001b[0;34m(model, start_time, end_time, inputs, controls, top_p, debug, delta, instruments, num_beams, K_total, K_time, K_dur, K_note)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0;32mcontinue\u001b[0m \u001b[0;31m#don't do the branching\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             new_triples, logps = topk_triples(model, z, beam.tokens, max(start_time,beam.current_time), instruments=instruments, K_total=K_total,\n\u001b[0m\u001b[1;32m    121\u001b[0m                                               debug=debug, K_time=K_time, K_dur=K_dur, K_note=K_note, top_p=None)\n\u001b[1;32m    122\u001b[0m             \u001b[0;31m#also has default parameters (debug=False, K_time=4, K_dur=2, K_note=2, K_total=8, top_p=None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-4117359698.py\u001b[0m in \u001b[0;36mtopk_triples\u001b[0;34m(model, z, tokens, current_time, instruments, debug, K_time, K_dur, K_note, K_total, top_p)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m#TIME TOKEN: generate K_time possibilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0minp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m         \u001b[0mlogits_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#(1, L, V) -> just shape V\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mlogits_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_masks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp_len\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAcceleratorError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constrain the beam search: now force injecting a note\n",
        "- exact note with given time and duration\n",
        "- a pitch within a specified time window\n",
        "- a pitch anywhere within the sequence\n",
        "\n",
        "The plan is to add the desired note as a possibility while branching, and prioritize beams which contain the note (after sorting candidates, use quota)\n",
        "\n",
        "In future want to extend this to chord progressions, etc\n",
        "\n",
        "- grid beam search (bins by how many constraints satisfied)\n",
        "- dynamic (fractional) allocation\n",
        "- alternatively, weight the logit for that token option by a lot?\n"
      ],
      "metadata": {
        "id": "TOa9yFErcSrj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class PitchWindow:\n",
        "    pitch: int\n",
        "    window_start: float\n",
        "    window_end: float"
      ],
      "metadata": {
        "id": "gZzKCI5xcazD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def topk_triples_constrained(model, z, tokens, current_time, instruments, forced_note, debug=False, K_time=4, K_dur=2, K_note=2, K_total=8, top_p=None):\n",
        "    assert len(tokens) % 3 == 0\n",
        "\n",
        "    device=model.device\n",
        "\n",
        "    history = tokens.copy()\n",
        "    lookback = max(len(tokens) - 1017, 0)\n",
        "    history = history[lookback:] # Markov window\n",
        "    offset = ops.min_time(history, seconds=False)\n",
        "    history[::3] = [tok - offset for tok in history[::3]] # relativize time in the history buffer\n",
        "\n",
        "    def apply_masks(logits, phase_idx, inp_len, tokens): #uhhh compared to original code inp_len is basically input_tokens.shape[1]\n",
        "        logits = safe_logits(logits, inp_len - 1)\n",
        "        if phase_idx == 0:\n",
        "            logits = future_logits(logits, current_time - offset)\n",
        "        elif phase_idx == 2:\n",
        "            logits = instr_logits_part1(logits, tokens, instruments)\n",
        "        if top_p is not None:\n",
        "            logits = nucleus(logits, top_p)\n",
        "        return logits\n",
        "\n",
        "    with torch.no_grad():\n",
        "        #TIME TOKEN: generate K_time possibilities\n",
        "        inp0 = torch.tensor(z + history, device=device).unsqueeze(0)\n",
        "        logits_t = model(inp0).logits[0, -1] #(1, L, V) -> just shape V\n",
        "        logits_t = apply_masks(logits_t, phase_idx=0, inp_len=inp0.shape[1], tokens=tokens)\n",
        "        logp_t = torch.log_softmax(logits_t, dim=-1)\n",
        "        t_vals, t_ids = torch.topk(logp_t, K_time)\n",
        "        t_ids = t_ids.tolist(); t_vals = t_vals.tolist()\n",
        "\n",
        "        #DURATION TOKEN (batch over K_time)\n",
        "        #build batch prefixes: z + history + [t_i]\n",
        "        batch_time_inputs = [z + history + [t] for t in t_ids]\n",
        "        inp1 = torch.nn.utils.rnn.pad_sequence(\n",
        "            [torch.tensor(x, device=device) for x in batch_time_inputs],\n",
        "            batch_first=True\n",
        "        )\n",
        "        logits_d_all = model(inp1).logits[:, -1, :] #[K_time, L, V] -> [K_time, V]\n",
        "        logp_d_all = []\n",
        "        d_ids_all  = []\n",
        "        for row, base_len in zip(logits_d_all, [len(x) for x in batch_time_inputs]):\n",
        "            row = apply_masks(row, phase_idx=1, inp_len=base_len, tokens=tokens)\n",
        "            #note tokens is the \"old\" full history but it's ok here, the only thing apply_masks\n",
        "            #passes it into is instr_logit which cares about instrument history we're chilling\n",
        "            lp = torch.log_softmax(row, dim=-1)\n",
        "            d_vals, d_ids = torch.topk(lp, K_dur) #take top K_dur options\n",
        "            logp_d_all.append(d_vals)\n",
        "            d_ids_all.append(d_ids)\n",
        "        #shapes end up being lists of K_time tensors, each [K_dur]\n",
        "\n",
        "        #NOTE TOKEN (batch over K_time *K_dur)\n",
        "        td_pairs = []\n",
        "        td_logps = []\n",
        "        td_inputs = []\n",
        "        for i in range(len(t_ids)): #K_time outer loop\n",
        "            for j in range(K_dur): #K_dur inner loop\n",
        "                time_token_id = t_ids[i] #token id\n",
        "                lp_time = t_vals[i] #log prob for that token\n",
        "                dur_token_id = d_ids_all[i][j].item()\n",
        "                lp_dur = logp_d_all[i][j].item()\n",
        "                td_pairs.append((time_token_id, dur_token_id, lp_time, lp_dur))\n",
        "                td_inputs.append(z + history + [time_token_id, dur_token_id])\n",
        "\n",
        "        inp2 = torch.nn.utils.rnn.pad_sequence( #batched processing (K_time*K_dur) batches\n",
        "            [torch.tensor(x, device=device) for x in td_inputs],\n",
        "            batch_first=True\n",
        "        )\n",
        "        logits_n_all = model(inp2).logits[:, -1, :] #(K_time*K_dur, L, V) -> (K_time*K_dur, V)\n",
        "\n",
        "        candidates = []  # (triple_ids, joint_logp)\n",
        "        idx = 0\n",
        "        forced_candidate = None\n",
        "\n",
        "        for i in range(len(t_ids)): #K_time\n",
        "            for j in range(K_dur): #K_dur\n",
        "                row = logits_n_all[idx]\n",
        "                idx += 1 #counts up to K_time*K_dur\n",
        "                base_len = len(td_inputs[i*K_dur + j])\n",
        "                row = apply_masks(row, phase_idx=2, inp_len=base_len, tokens=tokens)\n",
        "                lp = torch.log_softmax(row, dim=-1)\n",
        "                note_vals, note_ids = torch.topk(lp, K_note) #pick top K_note options\n",
        "                time_token_id, dur_token_id, lp_time, lp_dur = td_pairs[i*K_dur + j]\n",
        "                for k in range(K_note):\n",
        "                    note_token_id = note_ids[k].item()\n",
        "                    lp_note = note_vals[k].item()\n",
        "                    joint = lp_time + lp_dur + lp_note\n",
        "                    candidates.append(([time_token_id, dur_token_id, note_token_id], joint))\n",
        "\n",
        "                forced_joint_lp = lp_time + lp_dur + lp[forced_note].item()\n",
        "                if forced_candidate is None or forced_joint_lp > forced_candidate[1]:\n",
        "                    forced_candidate = ([time_token_id, dur_token_id, forced_note], forced_joint_lp)\n",
        "\n",
        "        def dedup(candidates):\n",
        "            unique = {}\n",
        "            for note_choice, logprob in candidates:\n",
        "                key = tuple(note_choice)\n",
        "                if key not in unique or logprob > unique[key]:\n",
        "                    unique[key] = logprob #tuplify the array of 3\n",
        "            return [(list(key), unique[key]) for key in unique.keys()]\n",
        "\n",
        "        candidates = dedup(candidates) #remove duplicates hopefully this helps\n",
        "\n",
        "        #candidates has list of triples ([time token, dur token, note token], prob)\n",
        "        joint_logps = torch.tensor([logprob for _, logprob in candidates], device=device)\n",
        "        #gumbel top k sampling, basically the idea is you add random noise before you take the top k\n",
        "        u = torch.rand_like(joint_logps)\n",
        "        g = -torch.log(-torch.log(u))              # Gumbel(0,1)\n",
        "        tau = 1.0                                  # temperature: 1.0–1.5 = good range\n",
        "        scores = joint_logps / tau + g             # random jittered scores\n",
        "\n",
        "        #choose K_total without replacement (highest noised scores)\n",
        "        top = torch.topk(scores, K_total-1) #reserve 1 spot for the forced option\n",
        "        best = [candidates[i] for i in top.indices.tolist()]\n",
        "        #find the highest log prob one with a forced note\n",
        "        best.append(forced_candidate)\n",
        "\n",
        "        #ALTERNATIVELY, DETERMINISTIC TOP TOTAL_K -> tried this and it led to beam collapse\n",
        "        #candidates.sort(key=lambda x: x[1], reverse=True) #highest to lowest by joint prob\n",
        "        #best = candidates[:K_total]\n",
        "\n",
        "        triples = torch.tensor([ids for ids,_ in best], device=device, dtype=torch.long)  # [K_total, 3]\n",
        "        logps  = torch.tensor([lp  for _,lp in best], device=device, dtype=torch.float)   # [K_total]\n",
        "\n",
        "    #if TIME in history was relativized by `offset`, undo for output:\n",
        "    triples[:, 0] = triples[:, 0] + offset\n",
        "    print(\"triple of tokens option from single beam\", triples)\n",
        "\n",
        "    return triples, logps #FORMAT IS TENSOR OF SHAPES [K_total, 3] and [K_total]\n"
      ],
      "metadata": {
        "id": "gPnNe1Eac9Ul"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#first come up with a constrained beam subclass"
      ],
      "metadata": {
        "id": "KHSyRamjmz73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_beams_constrained(model, start_time, end_time, inputs=None, controls=None, top_p=None,\n",
        "                   debug=False, delta=DELTA*TIME_RESOLUTION, instruments=None,\n",
        "                   num_beams=10, K_total=10, K_time=5, K_dur=2, K_note=3):\n",
        "    if inputs is None:\n",
        "        inputs = []\n",
        "\n",
        "    if controls is None:\n",
        "        controls = []\n",
        "\n",
        "    start_time = int(TIME_RESOLUTION*start_time)\n",
        "    end_time = int(TIME_RESOLUTION*end_time)\n",
        "\n",
        "    # prompt is events up to start_time\n",
        "    prompt = ops.pad(ops.clip(inputs, 0, start_time, clip_duration=False, seconds=False), start_time)\n",
        "\n",
        "    # treat events beyond start_time as controls\n",
        "    future = ops.clip(inputs, start_time+1, ops.max_time(inputs, seconds=False), clip_duration=False, seconds=False)\n",
        "    if debug:\n",
        "        print('Future')\n",
        "        ops.print_tokens(future)\n",
        "\n",
        "    # clip controls that preceed the sequence\n",
        "    controls = ops.clip(controls, DELTA, ops.max_time(controls, seconds=False), clip_duration=False, seconds=False)\n",
        "\n",
        "    if debug:\n",
        "        print('Controls')\n",
        "        ops.print_tokens(controls)\n",
        "\n",
        "    z = [ANTICIPATE] if len(controls) > 0 or len(future) > 0 else [AUTOREGRESS]\n",
        "    if debug:\n",
        "        print('AR Mode' if z[0] == AUTOREGRESS else 'AAR Mode')\n",
        "\n",
        "    # interleave the controls with the events\n",
        "    tokens, controls = ops.anticipate(prompt, ops.sort(controls + [CONTROL_OFFSET+token for token in future]))\n",
        "\n",
        "    if debug:\n",
        "        print('Prompt')\n",
        "        ops.print_tokens(tokens)\n",
        "\n",
        "    current_time = ops.max_time(prompt, seconds=False)\n",
        "\n",
        "    if debug:\n",
        "        print('Current time:', current_time)\n",
        "\n",
        "    #ok now we make a list of beams each initializing tokens with the controls\n",
        "    beams = []\n",
        "    for _ in range(num_beams):\n",
        "        beams.append(Beam(\n",
        "          tokens=tokens.copy(),\n",
        "          control_tokens=controls.copy(),\n",
        "          anticip_time=(controls[0] - ATIME_OFFSET if controls else math.inf),\n",
        "          score=0.0,\n",
        "          current_time=current_time,\n",
        "          gen_len = 0\n",
        "        ))\n",
        "\n",
        "    #with tqdm(range(end_time-start_time)) as progress:\n",
        "    not_done = True\n",
        "    counter = -1\n",
        "    phrase = 3\n",
        "\n",
        "    while not_done:\n",
        "\n",
        "        counter += 1\n",
        "        candidates = []\n",
        "        unique_beams = {}\n",
        "        not_done = False\n",
        "\n",
        "        for idx, beam in enumerate(beams): #for every add a token triplet in each one which hasn't finished\n",
        "\n",
        "            #directly add the finished beams\n",
        "            if beam.current_time >= end_time:\n",
        "                candidates.append(beam)\n",
        "                continue\n",
        "\n",
        "            not_done = True #if at least one beam gets token added, then not done\n",
        "            #last pass not_done will be False if every beam is done\n",
        "            print(\"beam\", idx, \"has current time\", beam.current_time, \"tokens\", beam.tokens)\n",
        "            print(\"anticipated_time\", beam.anticip_time, \"end_time\", end_time)\n",
        "\n",
        "            #directly mutate control_tokens, anticip_time\n",
        "            while beam.current_time >= beam.anticip_time - delta:\n",
        "\n",
        "                if not beam.control_tokens:\n",
        "                    break\n",
        "\n",
        "                atime, adur, anote = beam.control_tokens[:3]\n",
        "                beam.tokens.extend([atime, adur, anote])\n",
        "                beam.control_tokens = beam.control_tokens[3:]\n",
        "\n",
        "                if debug:\n",
        "                    note = anote - ANOTE_OFFSET\n",
        "                    instr = note//2**7\n",
        "                    print('A', atime - ATIME_OFFSET, adur - ADUR_OFFSET, instr, note - (2**7)*instr)\n",
        "\n",
        "                if len(beam.control_tokens) > 0:\n",
        "                    beam.anticip_time = beam.control_tokens[0] - ATIME_OFFSET\n",
        "                else:\n",
        "                    beam.anticip_time = math.inf\n",
        "\n",
        "            if counter % phrase != 0: #just generate normally rather than branching on this triplet\n",
        "                new_token, new_token_score = add_token_part1_modified(model, z, beam.tokens, top_p=top_p,\n",
        "                                            current_time=max(start_time, beam.current_time),\n",
        "                                            instruments=instruments, debug=True)\n",
        "                if new_token[0] < end_time: #new token's time\n",
        "                      possible_beam = Beam(\n",
        "                          tokens=beam.tokens.copy() + new_token,\n",
        "                          control_tokens=beam.control_tokens[:],\n",
        "                          anticip_time = beam.anticip_time,\n",
        "                          score=beam.score + new_token_score,\n",
        "                          current_time=new_token[0],\n",
        "                          gen_len = beam.gen_len+3\n",
        "                      )\n",
        "                      candidates.append(possible_beam)\n",
        "                else:\n",
        "                    candidates.append(beam)\n",
        "\n",
        "                continue #don't do the branching\n",
        "\n",
        "            new_triples, logps = topk_triples(model, z, beam.tokens, max(start_time,beam.current_time), instruments=instruments, K_total=K_total,\n",
        "                                              debug=debug, K_time=K_time, K_dur=K_dur, K_note=K_note, top_p=None)\n",
        "            #also has default parameters (debug=False, K_time=4, K_dur=2, K_note=2, K_total=8, top_p=None)\n",
        "            #shapes [K_total, 3] and [K_total]\n",
        "\n",
        "            for row, logp in zip(new_triples, logps):\n",
        "\n",
        "                  new_time = row[0].item() - TIME_OFFSET\n",
        "                  if new_time < beam.current_time:\n",
        "                      continue\n",
        "\n",
        "                  if new_time < end_time:\n",
        "                      possible_beam = Beam(\n",
        "                          tokens=beam.tokens.copy() + [token.item() for token in row],\n",
        "                          control_tokens=beam.control_tokens[:],\n",
        "                          anticip_time = beam.anticip_time,\n",
        "                          score=beam.score + logp.item(),\n",
        "                          current_time=new_time, #the new time, don't actually mutate new_triples\n",
        "                          gen_len = beam.gen_len+3\n",
        "                      )\n",
        "                  else: #DON'T ACTUALLY APPEND THAT TRIPLE, though anticipation has been mutated\n",
        "                      possible_beam = Beam(\n",
        "                          tokens=beam.tokens.copy(),\n",
        "                          control_tokens=beam.control_tokens[:],\n",
        "                          anticip_time = beam.anticip_time,\n",
        "                          score=beam.score,\n",
        "                          current_time=new_time, #terminal beam candidate, kill it from growing to prevent inf loop\n",
        "                          gen_len=beam.gen_len\n",
        "                      )\n",
        "\n",
        "                  if tuple(possible_beam.tokens) not in unique_beams: #DEDUP\n",
        "                      unique_beams[tuple(possible_beam.tokens)] = True\n",
        "                      candidates.append(possible_beam)\n",
        "\n",
        "            if debug:\n",
        "                print(\"print data about the new triples generated?\")\n",
        "                #new_note = new_token[2] - NOTE_OFFSET\n",
        "                #new_instr = new_note//2**7\n",
        "                #new_pitch = new_note - (2**7)*new_instr\n",
        "                #print('C', new_time, new_token[1] - DUR_OFFSET, new_instr, new_pitch)\n",
        "\n",
        "        def rank(b, alpha=0.5, gamma=0.01, empty_penalty=1e6, start_tick=0):\n",
        "            #normalize for length\n",
        "            base = b.score / (max(1, b.gen_len) ** alpha)\n",
        "\n",
        "            #favor beams that advance forward in time\n",
        "            #be careful to scale gamma to your tick units / seconds, start_tick is start_time in ticks\n",
        "            prog = gamma * max(0, b.current_time - start_tick)\n",
        "\n",
        "            #add penalty for empty generations so that we don't just end up with prompt and nothing else\n",
        "            if b.gen_len == 0:\n",
        "                return base + prog - empty_penalty\n",
        "\n",
        "            return base + prog\n",
        "\n",
        "        candidates.sort(key=lambda b: rank(b), reverse=True) #highest to lowest by score, in-place sort\n",
        "        beams = candidates[:num_beams]\n",
        "        # for beam in beams:\n",
        "        #     print(\"current time\", beam.current_time, \"tokens\", beam.tokens)\n",
        "\n",
        "\n",
        "    #NOW CHOOSE FINAl OUTPUT OFF OF BEAMS LIST\n",
        "    if beams:\n",
        "        best_tokens = beams[0].tokens\n",
        "    else:\n",
        "        best_tokens = tokens\n",
        "\n",
        "    print(\"best_tokens\", best_tokens)\n",
        "    events, _ = ops.split(best_tokens)\n",
        "    return ops.sort(ops.unpad(events) + future)"
      ],
      "metadata": {
        "id": "9ma9ryzNmOU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions which evaluate musical characteristics of a beam:\n",
        "- Valence (positive/negative feel) heuristics: Major mode, diatonic pitch use, strong authentic cadences, fewer dissonances → higher valence. Minor/mode mixture, frequent chromatic alterations, larger fifths-distance jumps, deceptive cadences → lower valence.\n",
        "\n",
        "- Energy heuristics: Higher tempo, higher note density, strong accents (velocity), more syncopation, wider ambitus, more leaps → higher. Slower tempo, legato (high articulation ratio), low density, stable harmonic rhythm → lower.\n",
        "\n",
        "Brightness (symbolic): more high-register usage, open intervals (5ths, 6ths), triadic purity → “brighter.”\n",
        "\n",
        "Tension/Release: tonal-centroid distance spikes, dissonance rate, unresolved suspensions → “tense/anxious”; stable tonality + cadences → “calm/resolved.”"
      ],
      "metadata": {
        "id": "ZM8iKXz-Uy7E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use JordanAI model\n"
      ],
      "metadata": {
        "id": "S2CVxRhuINcU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q transformers huggingface_hub\n",
        "from huggingface_hub import login\n",
        "\n",
        "login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "502ee24939ae45c4a92aa8fd7543e277",
            "6aa381a901e74c16a6a12332fe1f0ba0",
            "02a7f05946d5420bb51b29959b9f02b7",
            "75ee74ee81e04aabadd8d0553dcc62f2",
            "219aac22ddee4014bdc5e23652225553",
            "318a82c2379f467da35973919a0f5051",
            "a7e3bb5f2e034eb4a92d9ae1bd1323fa",
            "99610d4dd7214535af16692433252029",
            "8068d80be44248bdb3ae887691c0173f",
            "b859fa8422a248c88e1515af263a9e6b",
            "cd769047da2e4d40a4eea2bd1a848c06",
            "7ce501b7397a4b33b067170e35d25997",
            "fe7d2e496a3142578a6ea585615cc43d",
            "5a86b62a2ed84900bb3d8e20ab7a1070",
            "fed3df4a2119440abf76c4835d803fc7",
            "be30aa9dbfd04d9dbbcd48d5693f2b56",
            "7546456bdcc94d4b9cbb82d8807008e2",
            "52ea1c9c653b4e54bae594e9b0df342d",
            "24561ea3c6e64646b674a60f317ae518",
            "07d4239d2ea5478f9b8c0b4fa08b4cd2"
          ]
        },
        "id": "OFhhnM_TL7Bb",
        "outputId": "384d967b-ee0c-4a7d-cda9-f02f715323e4"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "502ee24939ae45c4a92aa8fd7543e277"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "model_id = \"mitmedialab/JordanAI-pianoTrading-v0.1-pytorch\"\n",
        "\n",
        "jordan_model = AutoModelForCausalLM.from_pretrained(model_id, token=True, trust_remote_code=True).to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "09f390cb2a0e49fba51ccc9248f6b1ac",
            "23ca6b6077844165ae6935f1c76ef0f6",
            "a01e9bba7af0488a991b3a1fe80e59e2",
            "f843429fbaa54ab3b52e418c4b1ea45c",
            "02772708b779489fbd3016f8cece4be8",
            "1c53dabe97da42f4b2fade36074f9a4b",
            "07a3e849b8c34718b985eebcdb4708c9",
            "776603012228490794d738b4fcbcbc4c",
            "2b0ad9a9b1e94ced86fef42761705af5",
            "65d2b7066bcd45d4abf156e8e8ecdadc",
            "59a2b0d988b948998207cbff18eef0f7",
            "2cacb6295f6949f9ab7f4f27ab66d5bb",
            "82a7357516b1417b892c404e8e2425c0",
            "0ca54ee5c4f14e899125704bc5d8a7ec",
            "abf880e81d4d4f5381e5301c1b3d77bf",
            "8f79ae468c1e4cc1b6ec65ac2150cd17",
            "2f6fd9cbcf334d67a4ff158f17bea8b1",
            "d939f6f2b2be47dea7cd4cc825a0066b",
            "57b3d5bded11491b95e9d66bba0d16fd",
            "508095c4147641b8998b1488d0973e44",
            "7e9ca2480bdb46e69ce639e575c6cf26",
            "fe62587e496045d9bf4307663df694a0"
          ]
        },
        "id": "iPBMJ18mIDSU",
        "outputId": "20e7dabe-7ae2-4930-8e5e-db8e3c03508a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.98k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09f390cb2a0e49fba51ccc9248f6b1ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/1.44G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cacb6295f6949f9ab7f4f27ab66d5bb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_tokens= generate_beams(jordan_model, start_time=0, end_time=60, top_p=.98, instruments={1}, debug=False,\n",
        "                              num_beams=10, K_total=10, K_time=5, K_dur=2, K_note=5) #K_total is branch factor\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eK3OvMlGQRj_",
        "outputId": "33738a90-33d0-4c62-81ce-4ffd17534952"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "beam 0 has current time 0 tokens []\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[    0, 10030, 11206],\n",
            "        [    0, 10030, 11176],\n",
            "        [    0, 10028, 11176],\n",
            "        [    0, 10028, 11175],\n",
            "        [    0, 10030, 11205],\n",
            "        [    0, 10030, 11175],\n",
            "        [    0, 10028, 11202],\n",
            "        [    0, 10030, 11202],\n",
            "        [    0, 10028, 11205],\n",
            "        [    0, 10028, 11206]], device='cuda:0')\n",
            "beam 1 has current time 0 tokens []\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[    0, 10028, 11202],\n",
            "        [    0, 10028, 11176],\n",
            "        [    0, 10028, 11206],\n",
            "        [    0, 10030, 11176],\n",
            "        [    0, 10030, 11202],\n",
            "        [    0, 10028, 11205],\n",
            "        [    0, 10030, 11205],\n",
            "        [    0, 10028, 11175],\n",
            "        [    0, 10030, 11175],\n",
            "        [    0, 10030, 11206]], device='cuda:0')\n",
            "beam 2 has current time 0 tokens []\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[    0, 10030, 11175],\n",
            "        [    0, 10028, 11175],\n",
            "        [    0, 10028, 11205],\n",
            "        [    0, 10030, 11205],\n",
            "        [    0, 10028, 11202],\n",
            "        [    0, 10028, 11206],\n",
            "        [    0, 10028, 11176],\n",
            "        [    0, 10030, 11176],\n",
            "        [    0, 10030, 11206],\n",
            "        [    0, 10030, 11202]], device='cuda:0')\n",
            "beam 3 has current time 0 tokens []\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[    0, 10030, 11206],\n",
            "        [    0, 10028, 11176],\n",
            "        [    0, 10030, 11205],\n",
            "        [    0, 10028, 11205],\n",
            "        [    0, 10028, 11202],\n",
            "        [    0, 10030, 11202],\n",
            "        [    0, 10030, 11176],\n",
            "        [    0, 10028, 11206],\n",
            "        [    0, 10030, 11175],\n",
            "        [    0, 10028, 11175]], device='cuda:0')\n",
            "beam 4 has current time 0 tokens []\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[    0, 10028, 11202],\n",
            "        [    0, 10028, 11205],\n",
            "        [    0, 10028, 11175],\n",
            "        [    0, 10028, 11206],\n",
            "        [    0, 10028, 11176],\n",
            "        [    0, 10030, 11176],\n",
            "        [    0, 10030, 11205],\n",
            "        [    0, 10030, 11202],\n",
            "        [    0, 10030, 11175],\n",
            "        [    0, 10030, 11206]], device='cuda:0')\n",
            "beam 5 has current time 0 tokens []\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[    0, 10030, 11206],\n",
            "        [    0, 10030, 11176],\n",
            "        [    0, 10028, 11176],\n",
            "        [    0, 10030, 11202],\n",
            "        [    0, 10030, 11175],\n",
            "        [    0, 10028, 11202],\n",
            "        [    0, 10028, 11206],\n",
            "        [    0, 10028, 11205],\n",
            "        [    0, 10030, 11205],\n",
            "        [    0, 10028, 11175]], device='cuda:0')\n",
            "beam 6 has current time 0 tokens []\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[    0, 10030, 11176],\n",
            "        [    0, 10028, 11202],\n",
            "        [    0, 10030, 11202],\n",
            "        [    0, 10030, 11205],\n",
            "        [    0, 10028, 11205],\n",
            "        [    0, 10028, 11175],\n",
            "        [    0, 10030, 11206],\n",
            "        [    0, 10028, 11176],\n",
            "        [    0, 10030, 11175],\n",
            "        [    0, 10028, 11206]], device='cuda:0')\n",
            "beam 7 has current time 0 tokens []\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[    0, 10028, 11202],\n",
            "        [    0, 10030, 11205],\n",
            "        [    0, 10030, 11175],\n",
            "        [    0, 10028, 11176],\n",
            "        [    0, 10030, 11176],\n",
            "        [    0, 10028, 11175],\n",
            "        [    0, 10028, 11205],\n",
            "        [    0, 10030, 11202],\n",
            "        [    0, 10030, 11206],\n",
            "        [    0, 10028, 11206]], device='cuda:0')\n",
            "beam 8 has current time 0 tokens []\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[    0, 10030, 11176],\n",
            "        [    0, 10030, 11175],\n",
            "        [    0, 10028, 11176],\n",
            "        [    0, 10028, 11202],\n",
            "        [    0, 10028, 11175],\n",
            "        [    0, 10028, 11205],\n",
            "        [    0, 10028, 11206],\n",
            "        [    0, 10030, 11205],\n",
            "        [    0, 10030, 11202],\n",
            "        [    0, 10030, 11206]], device='cuda:0')\n",
            "beam 9 has current time 0 tokens []\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[    0, 10030, 11202],\n",
            "        [    0, 10030, 11206],\n",
            "        [    0, 10028, 11202],\n",
            "        [    0, 10028, 11175],\n",
            "        [    0, 10028, 11205],\n",
            "        [    0, 10028, 11176],\n",
            "        [    0, 10030, 11176],\n",
            "        [    0, 10030, 11175],\n",
            "        [    0, 10028, 11206],\n",
            "        [    0, 10030, 11205]], device='cuda:0')\n",
            "beam 0 has current time 0 tokens [0, 10030, 11176]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 3, TIME = [0]\n",
            "new token:  51 10030 11176 score:  -3.991131566464901\n",
            "beam 1 has current time 0 tokens [0, 10028, 11176]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 3, TIME = [0]\n",
            "new token:  4696 10515 11195 score:  -16.24416208267212\n",
            "beam 2 has current time 0 tokens [0, 10028, 11175]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 3, TIME = [0]\n",
            "new token:  0 10029 11203 score:  -5.973132073879242\n",
            "beam 3 has current time 0 tokens [0, 10030, 11175]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 3, TIME = [0]\n",
            "new token:  48 10030 11176 score:  -3.73803448677063\n",
            "beam 4 has current time 0 tokens [0, 10030, 11202]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 3, TIME = [0]\n",
            "new token:  26 10024 11206 score:  -9.94658613204956\n",
            "beam 5 has current time 0 tokens [0, 10028, 11202]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 3, TIME = [0]\n",
            "new token:  1 10035 11193 score:  -10.883811593055725\n",
            "beam 6 has current time 0 tokens [0, 10030, 11205]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 3, TIME = [0]\n",
            "new token:  24 10030 11204 score:  -4.637133069336414\n",
            "beam 7 has current time 0 tokens [0, 10028, 11205]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 3, TIME = [0]\n",
            "new token:  1279 10027 11181 score:  -12.747584104537964\n",
            "beam 8 has current time 0 tokens [0, 10028, 11206]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 3, TIME = [0]\n",
            "new token:  258 10009 11208 score:  -9.271263241767883\n",
            "beam 9 has current time 0 tokens [0, 10030, 11206]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 3, TIME = [0]\n",
            "new token:  26 10018 11181 score:  -10.66927170753479\n",
            "beam 0 has current time 4696 tokens [0, 10028, 11176, 4696, 10515, 11195]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 6, TIME = [0, 4696]\n",
            "new token:  4975 10052 11176 score:  -5.7739231046289206\n",
            "beam 1 has current time 1279 tokens [0, 10028, 11205, 1279, 10027, 11181]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 6, TIME = [0, 1279]\n",
            "new token:  1706 10074 11186 score:  -12.081122875213623\n",
            "beam 2 has current time 51 tokens [0, 10030, 11176, 51, 10030, 11176]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 6, TIME = [0, 51]\n",
            "new token:  176 10026 11176 score:  -5.428123712539673\n",
            "beam 3 has current time 48 tokens [0, 10030, 11175, 48, 10030, 11176]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 6, TIME = [0, 48]\n",
            "new token:  381 10287 11192 score:  -13.280921697616577\n",
            "beam 4 has current time 258 tokens [0, 10028, 11206, 258, 10009, 11208]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 6, TIME = [0, 258]\n",
            "new token:  1688 10024 11195 score:  -14.840587615966797\n",
            "beam 5 has current time 24 tokens [0, 10030, 11205, 24, 10030, 11204]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 6, TIME = [0, 24]\n",
            "new token:  27 10047 11180 score:  -7.140422940254211\n",
            "beam 6 has current time 0 tokens [0, 10028, 11175, 0, 10029, 11203]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 6, TIME = [0, 0]\n",
            "new token:  27512 10076 11181 score:  -4.705027028918266\n",
            "beam 7 has current time 26 tokens [0, 10030, 11202, 26, 10024, 11206]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 6, TIME = [0, 26]\n",
            "new token:  226 10072 11185 score:  -12.695427179336548\n",
            "beam 8 has current time 26 tokens [0, 10030, 11206, 26, 10018, 11181]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 6, TIME = [0, 26]\n",
            "new token:  1771 10018 11199 score:  -8.22531770169735\n",
            "beam 9 has current time 1 tokens [0, 10028, 11202, 1, 10035, 11193]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 6, TIME = [0, 1]\n",
            "new token:  733 10019 11192 score:  -10.691910982131958\n",
            "beam 0 has current time 4975 tokens [0, 10028, 11176, 4696, 10515, 11195, 4975, 10052, 11176]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[27512, 10051, 11179],\n",
            "        [27512, 10046, 11194],\n",
            "        [27512, 10046, 11193],\n",
            "        [27512, 10051, 11188],\n",
            "        [27512, 10051, 11176],\n",
            "        [27512, 10051, 11196],\n",
            "        [27512, 10051, 11184],\n",
            "        [27512, 10046, 11199],\n",
            "        [27512, 10046, 11190],\n",
            "        [27512, 10046, 11189]], device='cuda:0')\n",
            "beam 1 has current time 1771 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 3851, 10018, 11169],\n",
            "        [ 2899, 10024, 11177],\n",
            "        [ 2899, 10024, 11174],\n",
            "        [ 3851, 10018, 11197],\n",
            "        [ 3851, 10018, 11181],\n",
            "        [ 2897, 10028, 11174],\n",
            "        [ 2897, 10028, 11177],\n",
            "        [ 2899, 10025, 11177],\n",
            "        [ 2899, 10025, 11174],\n",
            "        [ 2897, 10024, 11197]], device='cuda:0')\n",
            "beam 2 has current time 1688 tokens [0, 10028, 11206, 258, 10009, 11208, 1688, 10024, 11195]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 2038, 10000, 27512],\n",
            "        [ 1788, 10000, 27512],\n",
            "        [ 1788, 10024, 11206],\n",
            "        [ 2688, 10152, 11171],\n",
            "        [ 1738, 10026, 11193],\n",
            "        [ 2438, 10024, 11206],\n",
            "        [ 2438, 10022, 11208],\n",
            "        [ 1738, 10026, 11213],\n",
            "        [ 1738, 10028, 11171],\n",
            "        [ 1738, 10026, 11176]], device='cuda:0')\n",
            "beam 3 has current time 1706 tokens [0, 10028, 11205, 1279, 10027, 11181, 1706, 10074, 11186]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 1765, 10049, 11196],\n",
            "        [ 2115, 10031, 11206],\n",
            "        [ 2115, 10031, 11184],\n",
            "        [ 1765, 10016, 11191],\n",
            "        [ 2872, 10080, 11200],\n",
            "        [ 2872, 10080, 11199],\n",
            "        [ 2872, 10074, 11181],\n",
            "        [ 1722, 10280, 11209],\n",
            "        [ 1765, 10049, 11195],\n",
            "        [ 2115, 10049, 11193]], device='cuda:0')\n",
            "beam 4 has current time 733 tokens [0, 10028, 11202, 1, 10035, 11193, 733, 10019, 11192]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 1751, 10028, 11194],\n",
            "        [ 1747, 10033, 11202],\n",
            "        [ 1758, 10005, 11178],\n",
            "        [ 1747, 10033, 11197],\n",
            "        [ 1749, 10023, 11168],\n",
            "        [ 1758, 10023, 11169],\n",
            "        [ 1751, 10028, 11175],\n",
            "        [ 1751, 10028, 11169],\n",
            "        [ 1751, 10028, 11195],\n",
            "        [ 1749, 10017, 11193]], device='cuda:0')\n",
            "beam 5 has current time 176 tokens [0, 10030, 11176, 51, 10030, 11176, 176, 10026, 11176]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[  527, 10079, 11185],\n",
            "        [  526, 10000, 27512],\n",
            "        [  500, 10079, 11188],\n",
            "        [  500, 10079, 11185],\n",
            "        [  527, 10011, 11173],\n",
            "        [ 1500, 10026, 11178],\n",
            "        [ 1500, 10026, 11176],\n",
            "        [  427, 10091, 11191],\n",
            "        [  427, 10016, 11193],\n",
            "        [  526, 10011, 11176]], device='cuda:0')\n",
            "beam 6 has current time 381 tokens [0, 10030, 11175, 48, 10030, 11176, 381, 10287, 11192]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 6400, 10024, 11176],\n",
            "        [ 6550, 10024, 11176],\n",
            "        [ 6481, 10000, 27512],\n",
            "        [ 6513, 10018, 11176],\n",
            "        [ 6400, 10024, 11175],\n",
            "        [ 6400, 10024, 11139],\n",
            "        [ 6513, 10024, 11176],\n",
            "        [ 6388, 10006, 11192],\n",
            "        [ 6388, 10026, 11199],\n",
            "        [ 6388, 10006, 11187]], device='cuda:0')\n",
            "beam 7 has current time 0 tokens [0, 10028, 11175, 0, 10029, 11203]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[27512, 10076, 11192],\n",
            "        [27512, 10076, 11180],\n",
            "        [27512, 10076, 11197],\n",
            "        [27512, 10076, 11201],\n",
            "        [27512, 10076, 11199],\n",
            "        [27512, 10073, 11201],\n",
            "        [27512, 10073, 11187],\n",
            "        [27512, 10073, 11192],\n",
            "        [27512, 10073, 11180],\n",
            "        [   26, 10036, 11203]], device='cuda:0')\n",
            "beam 8 has current time 27 tokens [0, 10030, 11205, 24, 10030, 11204, 27, 10047, 11180]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[   50, 10030, 11200],\n",
            "        [   50, 10026, 11195],\n",
            "        [   50, 10030, 11196],\n",
            "        [   50, 10026, 11207],\n",
            "        [   47, 10026, 11195],\n",
            "        [   53, 10037, 11195],\n",
            "        [   50, 10030, 11195],\n",
            "        [   50, 10026, 11180],\n",
            "        [  550, 10011, 11197],\n",
            "        [   50, 10030, 11199]], device='cuda:0')\n",
            "beam 9 has current time 226 tokens [0, 10030, 11202, 26, 10024, 11206, 226, 10072, 11185]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[  858, 10014, 11176],\n",
            "        [ 2833, 10032, 11190],\n",
            "        [ 2758, 10024, 11208],\n",
            "        [  858, 10030, 11195],\n",
            "        [  258, 10031, 11209],\n",
            "        [ 2758, 10072, 11179],\n",
            "        [  258, 10032, 11194],\n",
            "        [  858, 10014, 11196],\n",
            "        [  508, 10028, 11176],\n",
            "        [ 2758, 10072, 11203]], device='cuda:0')\n",
            "beam 3 has current time 3851 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11181]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 12, TIME = [0, 26, 1771, 3851]\n",
            "new token:  4602 10030 11186 score:  -10.756003260612488\n",
            "beam 4 has current time 3851 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11169]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 12, TIME = [0, 26, 1771, 3851]\n",
            "new token:  9249 10024 11175 score:  -11.88105022907257\n",
            "beam 5 has current time 3851 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11197]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 12, TIME = [0, 26, 1771, 3851]\n",
            "new token:  4430 10011 11174 score:  -13.61496090888977\n",
            "beam 6 has current time 2899 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10024, 11177]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 12, TIME = [0, 26, 1771, 2899]\n",
            "new token:  3025 10040 11177 score:  -10.869054555892944\n",
            "beam 7 has current time 2899 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10024, 11174]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 12, TIME = [0, 26, 1771, 2899]\n",
            "new token:  27512 10084 11186 score:  -4.8274876922369\n",
            "beam 8 has current time 2899 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10025, 11174]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 12, TIME = [0, 26, 1771, 2899]\n",
            "new token:  3399 10026 11188 score:  -8.816338419914246\n",
            "beam 9 has current time 2897 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2897, 10024, 11197]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 12, TIME = [0, 26, 1771, 2897]\n",
            "new token:  3834 10057 11181 score:  -9.189607992768288\n",
            "beam 3 has current time 4602 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11181, 4602, 10030, 11186]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 15, TIME = [0, 26, 1771, 3851, 4602]\n",
            "new token:  4622 10032 11169 score:  -5.718076225370169\n",
            "beam 4 has current time 4430 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11197, 4430, 10011, 11174]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 15, TIME = [0, 26, 1771, 3851, 4430]\n",
            "new token:  4532 10011 11185 score:  -8.882596492767334\n",
            "beam 5 has current time 3851 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11169]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 12, TIME = [0, 26, 1771, 3851]\n",
            "new token:  8376 10024 11179 score:  -12.980128958821297\n",
            "beam 6 has current time 3834 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2897, 10024, 11197, 3834, 10057, 11181]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 15, TIME = [0, 26, 1771, 2897, 3834]\n",
            "new token:  6271 10034 11173 score:  -14.103385925292969\n",
            "beam 7 has current time 3399 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10025, 11174, 3399, 10026, 11188]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 15, TIME = [0, 26, 1771, 2899, 3399]\n",
            "new token:  3401 10029 11178 score:  -7.071953058242798\n",
            "beam 8 has current time 2899 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10024, 11174]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 12, TIME = [0, 26, 1771, 2899]\n",
            "new token:  27512 10031 11179 score:  -3.47148959338665\n",
            "beam 9 has current time 3025 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10024, 11177, 3025, 10040, 11177]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 15, TIME = [0, 26, 1771, 2899, 3025]\n",
            "new token:  5117 10240 11184 score:  -8.862609624862671\n",
            "beam 3 has current time 5117 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10024, 11177, 3025, 10040, 11177, 5117, 10240, 11184]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 5120, 10023, 11176],\n",
            "        [ 5617, 10084, 11184],\n",
            "        [ 5123, 10015, 11199],\n",
            "        [ 5121, 10129, 11197],\n",
            "        [ 5120, 10070, 11189],\n",
            "        [ 5121, 10022, 11194],\n",
            "        [ 5123, 10006, 11196],\n",
            "        [ 5121, 10129, 11200],\n",
            "        [ 5137, 10067, 11184],\n",
            "        [ 5123, 10006, 11199]], device='cuda:0')\n",
            "beam 4 has current time 4622 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11181, 4602, 10030, 11186, 4622, 10032, 11169]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 5117, 10009, 11181],\n",
            "        [ 5122, 10028, 11176],\n",
            "        [ 4623, 10032, 11205],\n",
            "        [ 5422, 10027, 11174],\n",
            "        [ 5472, 10029, 11171],\n",
            "        [ 4623, 10032, 11181],\n",
            "        [ 5422, 10027, 11203],\n",
            "        [ 5117, 10005, 11181],\n",
            "        [ 4623, 10032, 11214],\n",
            "        [ 4623, 10024, 11185]], device='cuda:0')\n",
            "beam 5 has current time 4532 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11197, 4430, 10011, 11174, 4532, 10011, 11185]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 5523, 10023, 11175],\n",
            "        [ 5502, 10019, 11175],\n",
            "        [ 5502, 10019, 11174],\n",
            "        [ 5502, 10020, 11177],\n",
            "        [ 5523, 10023, 11173],\n",
            "        [ 5875, 10019, 11175],\n",
            "        [ 5523, 10023, 11185],\n",
            "        [ 5538, 10025, 11177],\n",
            "        [ 5875, 10055, 11187],\n",
            "        [ 5538, 10025, 11175]], device='cuda:0')\n",
            "beam 6 has current time 3851 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11169]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 4601, 10016, 11176],\n",
            "        [ 4622, 10009, 11181],\n",
            "        [ 4608, 10024, 11176],\n",
            "        [ 4614, 10023, 11176],\n",
            "        [ 4608, 10024, 11213],\n",
            "        [ 4614, 10023, 11174],\n",
            "        [27512, 10017, 11181],\n",
            "        [ 4608, 10024, 11185],\n",
            "        [ 4622, 10018, 11176],\n",
            "        [ 4614, 10024, 11181]], device='cuda:0')\n",
            "beam 7 has current time 3834 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2897, 10024, 11197, 3834, 10057, 11181]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 4623, 10080, 11185],\n",
            "        [ 4627, 10025, 11195],\n",
            "        [ 3836, 10015, 11194],\n",
            "        [ 5846, 10030, 11169],\n",
            "        [ 4123, 10033, 11177],\n",
            "        [ 3836, 10015, 11195],\n",
            "        [ 4623, 10015, 11168],\n",
            "        [ 3836, 10015, 11168],\n",
            "        [ 4123, 10015, 11190],\n",
            "        [ 5846, 10033, 11188]], device='cuda:0')\n",
            "beam 8 has current time 3401 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10025, 11174, 3399, 10026, 11188, 3401, 10029, 11178]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 4176, 10032, 11197],\n",
            "        [ 3424, 10026, 11192],\n",
            "        [ 4176, 10030, 11183],\n",
            "        [ 3422, 10026, 11188],\n",
            "        [ 4174, 10026, 11192],\n",
            "        [ 3424, 10052, 11180],\n",
            "        [ 3426, 10055, 11178],\n",
            "        [ 4176, 10030, 11184],\n",
            "        [ 4174, 10026, 11197],\n",
            "        [ 3422, 10026, 11195]], device='cuda:0')\n",
            "beam 9 has current time 2899 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10024, 11174]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[27512, 10032, 11175],\n",
            "        [27512, 10031, 11177],\n",
            "        [27512, 10031, 11174],\n",
            "        [27512, 10031, 11198],\n",
            "        [27512, 10031, 11179],\n",
            "        [27512, 10031, 11175],\n",
            "        [27512, 10032, 11180],\n",
            "        [27512, 10032, 11177],\n",
            "        [ 3843, 10073, 11195],\n",
            "        [27512, 10032, 11188]], device='cuda:0')\n",
            "beam 5 has current time 5846 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2897, 10024, 11197, 3834, 10057, 11181, 5846, 10030, 11169]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 18, TIME = [26, 1771, 2897, 3834, 5846]\n",
            "new token:  6243 10041 11174 score:  -8.207880944013596\n",
            "beam 6 has current time 5846 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2897, 10024, 11197, 3834, 10057, 11181, 5846, 10033, 11188]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 18, TIME = [26, 1771, 2897, 3834, 5846]\n",
            "new token:  9355 10009 11193 score:  -15.254194378852844\n",
            "beam 7 has current time 5875 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11197, 4430, 10011, 11174, 4532, 10011, 11185, 5875, 10055, 11187]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 21, TIME = [1771, 3851, 4430, 4532, 5875]\n",
            "new token:  27512 10020 11174 score:  -2.9242103546857834\n",
            "beam 8 has current time 5875 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11197, 4430, 10011, 11174, 4532, 10011, 11185, 5875, 10019, 11175]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 21, TIME = [1771, 3851, 4430, 4532, 5875]\n",
            "new token:  6642 10069 11182 score:  -11.085720539093018\n",
            "beam 9 has current time 5617 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10024, 11177, 3025, 10040, 11177, 5117, 10240, 11184, 5617, 10084, 11184]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 21, TIME = [1771, 2899, 3025, 5117, 5617]\n",
            "new token:  8210 10037 11191 score:  -11.544404029846191\n",
            "beam 5 has current time 5846 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2897, 10024, 11197, 3834, 10057, 11181, 5846, 10030, 11169]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 18, TIME = [26, 1771, 2897, 3834, 5846]\n",
            "new token:  6272 10005 11174 score:  -6.073336601257324\n",
            "beam 6 has current time 5846 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2897, 10024, 11197, 3834, 10057, 11181, 5846, 10033, 11188]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 18, TIME = [26, 1771, 2897, 3834, 5846]\n",
            "new token:  8517 10037 11181 score:  -7.700314551591873\n",
            "beam 7 has current time 5875 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11197, 4430, 10011, 11174, 4532, 10011, 11185, 5875, 10055, 11187]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 21, TIME = [1771, 3851, 4430, 4532, 5875]\n",
            "new token:  27512 10076 11174 score:  -3.4232438653707504\n",
            "beam 8 has current time 5875 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11197, 4430, 10011, 11174, 4532, 10011, 11185, 5875, 10019, 11175]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 21, TIME = [1771, 3851, 4430, 4532, 5875]\n",
            "new token:  6625 10075 11182 score:  -7.464261054992676\n",
            "beam 9 has current time 5617 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10024, 11177, 3025, 10040, 11177, 5117, 10240, 11184, 5617, 10084, 11184]\n",
            "anticipated_time inf end_time 6000\n",
            "  OFFSET = 0, LEN = 21, TIME = [1771, 2899, 3025, 5117, 5617]\n",
            "new token:  5767 10028 11191 score:  -9.888378161936998\n",
            "beam 5 has current time 5846 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2897, 10024, 11197, 3834, 10057, 11181, 5846, 10030, 11169]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 6296, 10005, 11181],\n",
            "        [ 6360, 10016, 11168],\n",
            "        [ 6373, 10071, 11178],\n",
            "        [ 6296, 10065, 11174],\n",
            "        [ 6373, 10071, 11176],\n",
            "        [ 6373, 10068, 11176],\n",
            "        [ 6272, 10075, 11202],\n",
            "        [ 6271, 10032, 11181],\n",
            "        [ 6296, 10065, 11176],\n",
            "        [ 6360, 10011, 11184]], device='cuda:0')\n",
            "beam 6 has current time 5846 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2897, 10024, 11197, 3834, 10057, 11181, 5846, 10033, 11188]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 6379, 10036, 11194],\n",
            "        [27512, 10106, 11186],\n",
            "        [ 6360, 10148, 11186],\n",
            "        [ 5896, 10036, 11187],\n",
            "        [ 6379, 10142, 11162],\n",
            "        [ 6356, 10032, 11195],\n",
            "        [ 6379, 10142, 11174],\n",
            "        [ 5896, 10029, 11196],\n",
            "        [ 6360, 10136, 11186],\n",
            "        [ 5896, 10036, 11162]], device='cuda:0')\n",
            "beam 7 has current time 5875 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11197, 4430, 10011, 11174, 4532, 10011, 11185, 5875, 10055, 11187]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[27512, 10024, 11174],\n",
            "        [27512, 10018, 11181],\n",
            "        [27512, 10018, 11177],\n",
            "        [27512, 10018, 11182],\n",
            "        [27512, 10024, 11189],\n",
            "        [ 6375, 10055, 11196],\n",
            "        [27512, 10018, 11180],\n",
            "        [27512, 10018, 11171],\n",
            "        [ 6386, 10026, 11189],\n",
            "        [27512, 10024, 27512]], device='cuda:0')\n",
            "beam 8 has current time 5875 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 3851, 10018, 11197, 4430, 10011, 11174, 4532, 10011, 11185, 5875, 10019, 11175]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 6475, 10000, 27512],\n",
            "        [ 6875, 10019, 11187],\n",
            "        [ 6625, 10075, 11184],\n",
            "        [ 6725, 10000, 27512],\n",
            "        [ 6625, 10016, 11181],\n",
            "        [ 6375, 10016, 11187],\n",
            "        [ 6625, 10075, 11185],\n",
            "        [ 6475, 10024, 11181],\n",
            "        [ 6875, 10020, 11187],\n",
            "        [ 6475, 10024, 11197]], device='cuda:0')\n",
            "beam 9 has current time 5767 tokens [0, 10030, 11206, 26, 10018, 11181, 1771, 10018, 11199, 2899, 10024, 11177, 3025, 10040, 11177, 5117, 10240, 11184, 5617, 10084, 11184, 5767, 10028, 11191]\n",
            "anticipated_time inf end_time 6000\n",
            "triple of tokens option from single beam tensor([[ 6687, 10008, 11189],\n",
            "        [ 5837, 10010, 11191],\n",
            "        [ 6667, 10009, 11189],\n",
            "        [ 6643, 10021, 11180],\n",
            "        [ 6687, 10008, 11177],\n",
            "        [ 7122, 10055, 11179],\n",
            "        [ 5837, 10010, 11192],\n",
            "        [ 5837, 10032, 11177],\n",
            "        [ 6667, 10008, 11189],\n",
            "        [ 6667, 10009, 11165]], device='cuda:0')\n",
            "best_tokens [0, 10028, 11175, 0, 10029, 11203]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Audio(synthesize(fs, sample_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "Xon2SuBwbYV3",
        "outputId": "0cb595d2-7f88-4a9d-d493-284ed9bf46fb"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ],
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    }
  ]
}